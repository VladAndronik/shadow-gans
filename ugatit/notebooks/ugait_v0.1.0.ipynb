{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fBEKjtiMjJ9O"
   },
   "source": [
    "# Reproduce the original implementation with no changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "P4Mz5diejfHP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import init\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import functools\n",
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPl1GKACjzZv"
   },
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aHnYydZBj8AK"
   },
   "outputs": [],
   "source": [
    "class ResnetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, n_blocks=6, img_size=256, light=False):\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = ngf\n",
    "        self.n_blocks = n_blocks\n",
    "        self.img_size = img_size\n",
    "        self.light = light\n",
    "\n",
    "        DownBlock = []\n",
    "        DownBlock += [nn.ReflectionPad2d(3),\n",
    "                      nn.Conv2d(input_nc, ngf, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "                      nn.InstanceNorm2d(ngf),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        # Down-Sampling\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            DownBlock += [nn.ReflectionPad2d(1),\n",
    "                          nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "                          nn.InstanceNorm2d(ngf * mult * 2),\n",
    "                          nn.ReLU(True)]\n",
    "\n",
    "        # Down-Sampling Bottleneck\n",
    "        mult = 2**n_downsampling\n",
    "        for i in range(n_blocks):\n",
    "            DownBlock += [ResnetBlock(ngf * mult, use_bias=False)]\n",
    "\n",
    "        # Class Activation Map\n",
    "        self.gap_fc = nn.Linear(ngf * mult, 1, bias=False)\n",
    "        self.gmp_fc = nn.Linear(ngf * mult, 1, bias=False)\n",
    "        self.conv1x1 = nn.Conv2d(ngf * mult * 2, ngf * mult, kernel_size=1, stride=1, bias=True)\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "        # Gamma, Beta block\n",
    "        if self.light:\n",
    "            FC = [nn.Linear(ngf * mult, ngf * mult, bias=False),\n",
    "                  nn.ReLU(True),\n",
    "                  nn.Linear(ngf * mult, ngf * mult, bias=False),\n",
    "                  nn.ReLU(True)]\n",
    "        else:\n",
    "            FC = [nn.Linear(img_size // mult * img_size // mult * ngf * mult, ngf * mult, bias=False),\n",
    "                  nn.ReLU(True),\n",
    "                  nn.Linear(ngf * mult, ngf * mult, bias=False),\n",
    "                  nn.ReLU(True)]\n",
    "        self.gamma = nn.Linear(ngf * mult, ngf * mult, bias=False)\n",
    "        self.beta = nn.Linear(ngf * mult, ngf * mult, bias=False)\n",
    "\n",
    "        # Up-Sampling Bottleneck\n",
    "        for i in range(n_blocks):\n",
    "            setattr(self, 'UpBlock1_' + str(i+1), ResnetAdaILNBlock(ngf * mult, use_bias=False))\n",
    "\n",
    "        # Up-Sampling\n",
    "        UpBlock2 = []\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**(n_downsampling - i)\n",
    "            UpBlock2 += [nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                         nn.ReflectionPad2d(1),\n",
    "                         nn.Conv2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=1, padding=0, bias=False),\n",
    "                         ILN(int(ngf * mult / 2)),\n",
    "                         nn.ReLU(True)]\n",
    "\n",
    "        UpBlock2 += [nn.ReflectionPad2d(3),\n",
    "                     nn.Conv2d(ngf, output_nc, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "                     nn.Tanh()]\n",
    "\n",
    "        self.DownBlock = nn.Sequential(*DownBlock)\n",
    "        self.FC = nn.Sequential(*FC)\n",
    "        self.UpBlock2 = nn.Sequential(*UpBlock2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.DownBlock(input)\n",
    "\n",
    "        gap = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n",
    "        gap_logit = self.gap_fc(gap.view(x.shape[0], -1))\n",
    "        gap_weight = list(self.gap_fc.parameters())[0]\n",
    "        gap = x * gap_weight.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        gmp = torch.nn.functional.adaptive_max_pool2d(x, 1)\n",
    "        gmp_logit = self.gmp_fc(gmp.view(x.shape[0], -1))\n",
    "        gmp_weight = list(self.gmp_fc.parameters())[0]\n",
    "        gmp = x * gmp_weight.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        cam_logit = torch.cat([gap_logit, gmp_logit], 1)\n",
    "        x = torch.cat([gap, gmp], 1)\n",
    "        x = self.relu(self.conv1x1(x))\n",
    "\n",
    "        heatmap = torch.sum(x, dim=1, keepdim=True)\n",
    "\n",
    "        if self.light:\n",
    "            x_ = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n",
    "            x_ = self.FC(x_.view(x_.shape[0], -1))\n",
    "        else:\n",
    "            x_ = self.FC(x.view(x.shape[0], -1))\n",
    "        gamma, beta = self.gamma(x_), self.beta(x_)\n",
    "\n",
    "\n",
    "        for i in range(self.n_blocks):\n",
    "            x = getattr(self, 'UpBlock1_' + str(i+1))(x, gamma, beta)\n",
    "        out = self.UpBlock2(x)\n",
    "\n",
    "        return out, cam_logit, heatmap\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, use_bias):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        conv_block = []\n",
    "        conv_block += [nn.ReflectionPad2d(1),\n",
    "                       nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias),\n",
    "                       nn.InstanceNorm2d(dim),\n",
    "                       nn.ReLU(True)]\n",
    "\n",
    "        conv_block += [nn.ReflectionPad2d(1),\n",
    "                       nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias),\n",
    "                       nn.InstanceNorm2d(dim)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResnetAdaILNBlock(nn.Module):\n",
    "    def __init__(self, dim, use_bias):\n",
    "        super(ResnetAdaILNBlock, self).__init__()\n",
    "        self.pad1 = nn.ReflectionPad2d(1)\n",
    "        self.conv1 = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias)\n",
    "        self.norm1 = adaILN(dim)\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "\n",
    "        self.pad2 = nn.ReflectionPad2d(1)\n",
    "        self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias)\n",
    "        self.norm2 = adaILN(dim)\n",
    "\n",
    "    def forward(self, x, gamma, beta):\n",
    "        out = self.pad1(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.norm1(out, gamma, beta)\n",
    "        out = self.relu1(out)\n",
    "        out = self.pad2(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out, gamma, beta)\n",
    "\n",
    "        return out + x\n",
    "\n",
    "\n",
    "class adaILN(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5):\n",
    "        super(adaILN, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.rho = Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.rho.data.fill_(0.9)\n",
    "\n",
    "    def forward(self, input, gamma, beta):\n",
    "        in_mean, in_var = torch.mean(input, dim=[2, 3], keepdim=True), torch.var(input, dim=[2, 3], keepdim=True)\n",
    "        out_in = (input - in_mean) / torch.sqrt(in_var + self.eps)\n",
    "        ln_mean, ln_var = torch.mean(input, dim=[1, 2, 3], keepdim=True), torch.var(input, dim=[1, 2, 3], keepdim=True)\n",
    "        out_ln = (input - ln_mean) / torch.sqrt(ln_var + self.eps)\n",
    "        out = self.rho.expand(input.shape[0], -1, -1, -1) * out_in + (1-self.rho.expand(input.shape[0], -1, -1, -1)) * out_ln\n",
    "        out = out * gamma.unsqueeze(2).unsqueeze(3) + beta.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ILN(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5):\n",
    "        super(ILN, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.rho = Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.gamma = Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.beta = Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.rho.data.fill_(0.0)\n",
    "        self.gamma.data.fill_(1.0)\n",
    "        self.beta.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        in_mean, in_var = torch.mean(input, dim=[2, 3], keepdim=True), torch.var(input, dim=[2, 3], keepdim=True)\n",
    "        out_in = (input - in_mean) / torch.sqrt(in_var + self.eps)\n",
    "        ln_mean, ln_var = torch.mean(input, dim=[1, 2, 3], keepdim=True), torch.var(input, dim=[1, 2, 3], keepdim=True)\n",
    "        out_ln = (input - ln_mean) / torch.sqrt(ln_var + self.eps)\n",
    "        out = self.rho.expand(input.shape[0], -1, -1, -1) * out_in + (1-self.rho.expand(input.shape[0], -1, -1, -1)) * out_ln\n",
    "        out = out * self.gamma.expand(input.shape[0], -1, -1, -1) + self.beta.expand(input.shape[0], -1, -1, -1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=5):\n",
    "        super(Discriminator, self).__init__()\n",
    "        model = [nn.ReflectionPad2d(1),\n",
    "                 nn.utils.spectral_norm(\n",
    "                 nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=0, bias=True)),\n",
    "                 nn.LeakyReLU(0.2, True)]\n",
    "\n",
    "        for i in range(1, n_layers - 2):\n",
    "            mult = 2 ** (i - 1)\n",
    "            model += [nn.ReflectionPad2d(1),\n",
    "                      nn.utils.spectral_norm(\n",
    "                      nn.Conv2d(ndf * mult, ndf * mult * 2, kernel_size=4, stride=2, padding=0, bias=True)),\n",
    "                      nn.LeakyReLU(0.2, True)]\n",
    "\n",
    "        mult = 2 ** (n_layers - 2 - 1)\n",
    "        model += [nn.ReflectionPad2d(1),\n",
    "                  nn.utils.spectral_norm(\n",
    "                  nn.Conv2d(ndf * mult, ndf * mult * 2, kernel_size=4, stride=1, padding=0, bias=True)),\n",
    "                  nn.LeakyReLU(0.2, True)]\n",
    "\n",
    "        # Class Activation Map\n",
    "        mult = 2 ** (n_layers - 2)\n",
    "        self.gap_fc = nn.utils.spectral_norm(nn.Linear(ndf * mult, 1, bias=False))\n",
    "        self.gmp_fc = nn.utils.spectral_norm(nn.Linear(ndf * mult, 1, bias=False))\n",
    "        self.conv1x1 = nn.Conv2d(ndf * mult * 2, ndf * mult, kernel_size=1, stride=1, bias=True)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2, True)\n",
    "\n",
    "        self.pad = nn.ReflectionPad2d(1)\n",
    "        self.conv = nn.utils.spectral_norm(\n",
    "            nn.Conv2d(ndf * mult, 1, kernel_size=4, stride=1, padding=0, bias=False))\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "\n",
    "        gap = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n",
    "        gap_logit = self.gap_fc(gap.view(x.shape[0], -1))\n",
    "        gap_weight = list(self.gap_fc.parameters())[0]\n",
    "        gap = x * gap_weight.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        gmp = torch.nn.functional.adaptive_max_pool2d(x, 1)\n",
    "        gmp_logit = self.gmp_fc(gmp.view(x.shape[0], -1))\n",
    "        gmp_weight = list(self.gmp_fc.parameters())[0]\n",
    "        gmp = x * gmp_weight.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        cam_logit = torch.cat([gap_logit, gmp_logit], 1)\n",
    "        x = torch.cat([gap, gmp], 1)\n",
    "        x = self.leaky_relu(self.conv1x1(x))\n",
    "\n",
    "        heatmap = torch.sum(x, dim=1, keepdim=True)\n",
    "\n",
    "        x = self.pad(x)\n",
    "        out = self.conv(x)\n",
    "\n",
    "        return out, cam_logit, heatmap\n",
    "\n",
    "\n",
    "class RhoClipper(object):\n",
    "\n",
    "    def __init__(self, min, max):\n",
    "        self.clip_min = min\n",
    "        self.clip_max = max\n",
    "        assert min < max\n",
    "\n",
    "    def __call__(self, module):\n",
    "\n",
    "        if hasattr(module, 'rho'):\n",
    "            w = module.rho.data\n",
    "            w = w.clamp(self.clip_min, self.clip_max)\n",
    "            module.rho.data = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9200,
     "status": "ok",
     "timestamp": 1581898487756,
     "user": {
      "displayName": "Владислав Андроник",
      "photoUrl": "",
      "userId": "15929840215236502543"
     },
     "user_tz": -120
    },
    "id": "CEI4W5U7j9I9",
    "outputId": "a6c81dfc-b6fc-4795-a418-b67fc6048bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Summary models ----\n",
      "Number of parameters (in millions):\n",
      "D_L       D_G       G_LIGHT   G_HARD    Overall_LIGHT       Overall_HARD\n",
      "6.581     106.26    30.619    567.359   143.46              680.2     \n"
     ]
    }
   ],
   "source": [
    "# summary of the models\n",
    "def num_params(model):\n",
    "  model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "  params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "  return params\n",
    "\n",
    "dL = Discriminator(3, n_layers=5)\n",
    "dG = Discriminator(3, n_layers=7)\n",
    "g_light = ResnetGenerator(3,3, light=True)\n",
    "g_hard = ResnetGenerator(3,3, light=False)\n",
    "\n",
    "dL_num = round(num_params(dL) * 2 / 1e6, 3)\n",
    "dG_num = round(num_params(dG) * 2 / 1e6, 3)\n",
    "g_light_num = round(num_params(g_light) * 2 / 1e6, 3)\n",
    "g_hard_num = round(num_params(g_hard) * 2 / 1e6, 3)\n",
    "overall_light = round(dL_num + dG_num + g_light_num, 3)\n",
    "overall_hard = round(dL_num + dG_num + g_hard_num, 3)\n",
    "\n",
    "print('---- Summary models ----')\n",
    "print(\"Number of parameters (in millions):\")\n",
    "print(\"{:10}{:10}{:10}{:10}{:20}{:10}\".format(\"D_L\", 'D_G', \"G_LIGHT\", \"G_HARD\",\"Overall_LIGHT\", \"Overall_HARD\"))\n",
    "print(\"{:10}{:10}{:10}{:10}{:20}{:10}\".format(str(dL_num), str(dG_num), str(g_light_num), \n",
    "                                    str(g_hard_num), str(overall_light), str(overall_hard)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_4AxQHUkN1M"
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GqT9PyYXlIkA"
   },
   "outputs": [],
   "source": [
    "def load_test_data(image_path, size=256):\n",
    "    img = misc.imread(image_path, mode='RGB')\n",
    "    img = misc.imresize(img, [size, size])\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocessing(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "def preprocessing(x):\n",
    "    x = x/127.5 - 1 # -1 ~ 1\n",
    "    return x\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(inverse_transform(images), size, image_path)\n",
    "\n",
    "def inverse_transform(images):\n",
    "    return (images+1.) / 2\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return misc.imsave(path, merge(images, size))\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[h*j:h*(j+1), w*i:w*(i+1), :] = image\n",
    "\n",
    "    return img\n",
    "\n",
    "def check_folder(log_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    return log_dir\n",
    "\n",
    "def str2bool(x):\n",
    "    return x.lower() in ('true')\n",
    "\n",
    "def cam(x, size = 256):\n",
    "    x = x - np.min(x)\n",
    "    cam_img = x / np.max(x)\n",
    "    cam_img = np.uint8(255 * cam_img)\n",
    "    cam_img = cv2.resize(cam_img, (size, size))\n",
    "    cam_img = cv2.applyColorMap(cam_img, cv2.COLORMAP_JET)\n",
    "    return cam_img / 255.0\n",
    "\n",
    "def imagenet_norm(x):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.299, 0.224, 0.225]\n",
    "    mean = torch.FloatTensor(mean).unsqueeze(0).unsqueeze(2).unsqueeze(3).to(x.device)\n",
    "    std = torch.FloatTensor(std).unsqueeze(0).unsqueeze(2).unsqueeze(3).to(x.device)\n",
    "    return (x - mean) / std\n",
    "\n",
    "def denorm(x):\n",
    "    return x * 0.5 + 0.5\n",
    "\n",
    "def tensor2numpy(x):\n",
    "    return x.detach().cpu().numpy().transpose(1,2,0)\n",
    "\n",
    "def RGB2BGR(x):\n",
    "    return cv2.cvtColor(x, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzsEX2q8lTHa"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pTrCWFSYlVPQ"
   },
   "outputs": [],
   "source": [
    "def read_pil_image(path):\n",
    "  with open(path, 'rb') as f:\n",
    "    img = Image.open(f)\n",
    "    return img.convert(\"RGB\")\n",
    "\n",
    "\n",
    "class DatasetFolder(torch.utils.data.Dataset):\n",
    "  def __init__(self, root, extension, transform=None):\n",
    "    self.img_paths = glob.glob(os.path.join(root, '*.{}'.format(extension)))\n",
    "    self.img_len = len(self.img_paths)\n",
    "    assert self.img_len > 0, 'Found 0 images in {}'.format(root)\n",
    "    self.transform = transform\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    img = read_pil_image(self.img_paths[index % self.img_len])\n",
    "    img = self.transform(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.img_len\n",
    "\n",
    "\n",
    "class ImageFolder(DatasetFolder):\n",
    "  def __init__(self, root, extension, transform):\n",
    "    super(ImageFolder, self).__init__(root=root, \n",
    "                                      extension=extension, \n",
    "                                      transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDN2mIsjl_5o"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "JleuEXjHmiCE"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'ugatit/output/checkpoints/checkpoints_v0.1.0/'\n",
    "images_dir = 'ugatit/output/images/images_v0.1.0/'\n",
    "summary_dir = 'ugatit/output/summary/summary_v0.1.0/'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(summary_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "A_dir = 'data/shadow_USR/shadow_train/'\n",
    "B_dir = 'data/shadow_USR/shadow_free/'\n",
    "A_test_dir = 'data/shadow_USR/shadow_test/'\n",
    "\n",
    "\n",
    "\n",
    "load_model = True\n",
    "batch_size=1\n",
    "image_size=256\n",
    "ngf=64\n",
    "ndf=64\n",
    "light = True\n",
    "\n",
    "weight_adv = 1\n",
    "weight_cyc = 10\n",
    "weight_idt = 10\n",
    "# it might helps only generator to get attended, while discriminator does not use distinct cam loss\n",
    "weight_cam = 1000  \n",
    "\n",
    "\n",
    "learning_rate=2e-4\n",
    "beta1=.5\n",
    "pool_size=50\n",
    "mask_queue_size=50\n",
    "n_blocks=4\n",
    "slope=0.2\n",
    "stddev=0.02\n",
    "weight_decay=0.0001\n",
    "\n",
    "input_nc=3\n",
    "output_nc=3\n",
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "real_label=1.\n",
    "\n",
    "n_steps = int(3e5)\n",
    "decay_start = n_steps // 2\n",
    "decay_flag=True\n",
    "print_freq = 10\n",
    "save_freq = 5000\n",
    "test_freq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "R1AWk9TTpgkk"
   },
   "outputs": [],
   "source": [
    "def get_step(filename):\n",
    "  match = re.findall('(\\d+).pt', filename)[0]\n",
    "  return int(match)\n",
    "  \n",
    "def latest_checkpoint_files(check_dir, f):\n",
    "  return max(map(f, os.listdir(check_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rvdgCOWSmku2"
   },
   "outputs": [],
   "source": [
    "class UGATIT(object):\n",
    "  def __init__(self):\n",
    "    self.img_size=image_size\n",
    "    self.batch_size=batch_size\n",
    "    self.device=device\n",
    "    self.n_res=n_blocks\n",
    "    self.ch = ngf\n",
    "    self.light=light\n",
    "    self.lr = learning_rate\n",
    "    self.weight_decay = weight_decay\n",
    "\n",
    "    self.adv_weight = weight_adv\n",
    "    self.cycle_weight = weight_cyc\n",
    "    self.identity_weight = weight_idt\n",
    "    self.cam_weight = weight_cam\n",
    "\n",
    "\n",
    "  def build_model(self):\n",
    "    \"\"\" DataLoader \"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize((self.img_size + 30, self.img_size+30)),\n",
    "        transforms.RandomCrop(self.img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((self.img_size, self.img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    self.trainA = ImageFolder(A_dir, 'jpg', train_transform)\n",
    "    self.trainB = ImageFolder(B_dir, 'jpg', train_transform)\n",
    "    self.trainA_loader = DataLoader(self.trainA, batch_size=self.batch_size, shuffle=True)\n",
    "    self.trainB_loader = DataLoader(self.trainB, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    \"\"\" Define Generator, Discriminator \"\"\"\n",
    "    self.genA2B = ResnetGenerator(input_nc=3, output_nc=3, ngf=self.ch, \n",
    "                                  n_blocks=self.n_res, img_size=self.img_size, \n",
    "                                  light=self.light).to(self.device)\n",
    "    self.genB2A = ResnetGenerator(input_nc=3, output_nc=3, \n",
    "                                  ngf=self.ch, n_blocks=self.n_res, \n",
    "                                  img_size=self.img_size, light=self.light).to(self.device)\n",
    "    self.disGA = Discriminator(input_nc=3, ndf=self.ch, n_layers=7).to(self.device)\n",
    "    self.disGB = Discriminator(input_nc=3, ndf=self.ch, n_layers=7).to(self.device)\n",
    "    self.disLA = Discriminator(input_nc=3, ndf=self.ch, n_layers=5).to(self.device)\n",
    "    self.disLB = Discriminator(input_nc=3, ndf=self.ch, n_layers=5).to(self.device)\n",
    "\n",
    "    \"\"\" Define Loss \"\"\"\n",
    "    self.L1_loss = nn.L1Loss().to(self.device)\n",
    "    self.MSE_loss = nn.MSELoss().to(self.device)\n",
    "    self.BCE_loss = nn.BCEWithLogitsLoss().to(self.device)\n",
    "\n",
    "    \"\"\" Trainer \"\"\"\n",
    "    self.G_optim = torch.optim.Adam(itertools.chain(self.genA2B.parameters(), self.genB2A.parameters()), \n",
    "                                    lr=self.lr, betas=(0.5, 0.999), weight_decay=self.weight_decay)\n",
    "    self.D_optim = torch.optim.Adam(itertools.chain(self.disGA.parameters(), self.disGB.parameters(), \n",
    "                                                    self.disLA.parameters(), self.disLB.parameters()), \n",
    "                                    lr=self.lr, betas=(0.5, 0.999), weight_decay=self.weight_decay)\n",
    "\n",
    "    \"\"\" Define Rho clipper to constraint the value of rho in AdaILN and ILN\"\"\"\n",
    "    self.Rho_clipper = RhoClipper(0, 1)\n",
    "\n",
    "    \"\"\"Summary writing to tensorboard\"\"\"\n",
    "    self.writer = SummaryWriter(log_dir=summary_dir)\n",
    "\n",
    "\n",
    "  def train(self):\n",
    "    self.genA2B.train(), self.genB2A.train(), self.disGA.train(), self.disGB.train(), self.disLA.train(), self.disLB.train()\n",
    "\n",
    "    start_iter = 1\n",
    "    if load_model:\n",
    "      print(\"---- Loading the model ----\".upper())\n",
    "      model_list = glob.glob(os.path.join(checkpoint_dir, '*.pt'))\n",
    "      if len(model_list) > 0:\n",
    "        start_iter = latest_checkpoint_files(checkpoint_dir, get_step)\n",
    "        print('Load the model from {}'.format(start_iter))\n",
    "        self.load(checkpoint_dir, start_iter)\n",
    "        if decay_flag and start_iter > decay_start:\n",
    "          self.G_optim.param_groups[0]['lr'] -= (self.lr / decay_start) * (start_iter - decay_start)\n",
    "          self.D_optim.param_groups[0]['lr'] -= (self.lr / decay_start) * (start_iter - decay_start)\n",
    "        start_iter += 1  # for not repeating the start_iter step\n",
    "\n",
    "    # training loop\n",
    "    try:\n",
    "      print('training start !')\n",
    "      start_time = time.time()\n",
    "      counter=start_iter\n",
    "      for step in tqdm_notebook(range(start_iter, n_steps + 1), total=n_steps-start_iter):\n",
    "        if decay_flag and step > (n_steps // 2):\n",
    "            self.G_optim.param_groups[0]['lr'] -= (self.lr / (n_steps // 2))\n",
    "            self.D_optim.param_groups[0]['lr'] -= (self.lr / (n_steps // 2))\n",
    "\n",
    "        try:\n",
    "            real_A = trainA_iter.next()\n",
    "        except:\n",
    "            trainA_iter = iter(self.trainA_loader)\n",
    "            real_A = trainA_iter.next()\n",
    "\n",
    "        try:\n",
    "            real_B = trainB_iter.next()\n",
    "        except:\n",
    "            trainB_iter = iter(self.trainB_loader)\n",
    "            real_B = trainB_iter.next()\n",
    "\n",
    "        real_A, real_B = real_A.to(self.device), real_B.to(self.device)\n",
    "\n",
    "        # Update D\n",
    "        self.D_optim.zero_grad()\n",
    "\n",
    "        fake_A2B, _, _ = self.genA2B(real_A)\n",
    "        fake_B2A, _, _ = self.genB2A(real_B)\n",
    "\n",
    "        real_GA_logit, real_GA_cam_logit, _ = self.disGA(real_A)\n",
    "        real_LA_logit, real_LA_cam_logit, _ = self.disLA(real_A)\n",
    "        real_GB_logit, real_GB_cam_logit, _ = self.disGB(real_B)\n",
    "        real_LB_logit, real_LB_cam_logit, _ = self.disLB(real_B)\n",
    "\n",
    "        fake_GA_logit, fake_GA_cam_logit, _ = self.disGA(fake_B2A)\n",
    "        fake_LA_logit, fake_LA_cam_logit, _ = self.disLA(fake_B2A)\n",
    "        fake_GB_logit, fake_GB_cam_logit, _ = self.disGB(fake_A2B)\n",
    "        fake_LB_logit, fake_LB_cam_logit, _ = self.disLB(fake_A2B)\n",
    "\n",
    "        D_ad_loss_GA = self.MSE_loss(real_GA_logit, torch.ones_like(real_GA_logit).to(self.device)) + self.MSE_loss(fake_GA_logit, torch.zeros_like(fake_GA_logit).to(self.device))\n",
    "        D_ad_cam_loss_GA = self.MSE_loss(real_GA_cam_logit, torch.ones_like(real_GA_cam_logit).to(self.device)) + self.MSE_loss(fake_GA_cam_logit, torch.zeros_like(fake_GA_cam_logit).to(self.device))\n",
    "        D_ad_loss_LA = self.MSE_loss(real_LA_logit, torch.ones_like(real_LA_logit).to(self.device)) + self.MSE_loss(fake_LA_logit, torch.zeros_like(fake_LA_logit).to(self.device))\n",
    "        D_ad_cam_loss_LA = self.MSE_loss(real_LA_cam_logit, torch.ones_like(real_LA_cam_logit).to(self.device)) + self.MSE_loss(fake_LA_cam_logit, torch.zeros_like(fake_LA_cam_logit).to(self.device))\n",
    "        D_ad_loss_GB = self.MSE_loss(real_GB_logit, torch.ones_like(real_GB_logit).to(self.device)) + self.MSE_loss(fake_GB_logit, torch.zeros_like(fake_GB_logit).to(self.device))\n",
    "        D_ad_cam_loss_GB = self.MSE_loss(real_GB_cam_logit, torch.ones_like(real_GB_cam_logit).to(self.device)) + self.MSE_loss(fake_GB_cam_logit, torch.zeros_like(fake_GB_cam_logit).to(self.device))\n",
    "        D_ad_loss_LB = self.MSE_loss(real_LB_logit, torch.ones_like(real_LB_logit).to(self.device)) + self.MSE_loss(fake_LB_logit, torch.zeros_like(fake_LB_logit).to(self.device))\n",
    "        D_ad_cam_loss_LB = self.MSE_loss(real_LB_cam_logit, torch.ones_like(real_LB_cam_logit).to(self.device)) + self.MSE_loss(fake_LB_cam_logit, torch.zeros_like(fake_LB_cam_logit).to(self.device))\n",
    "\n",
    "        D_loss_A = self.adv_weight * (D_ad_loss_GA + D_ad_cam_loss_GA + D_ad_loss_LA + D_ad_cam_loss_LA)\n",
    "        D_loss_B = self.adv_weight * (D_ad_loss_GB + D_ad_cam_loss_GB + D_ad_loss_LB + D_ad_cam_loss_LB)\n",
    "\n",
    "        Discriminator_loss = D_loss_A + D_loss_B\n",
    "        Discriminator_loss.backward()\n",
    "        self.D_optim.step()\n",
    "\n",
    "        # Update G\n",
    "        self.G_optim.zero_grad()\n",
    "\n",
    "        fake_A2B, fake_A2B_cam_logit, _ = self.genA2B(real_A)\n",
    "        fake_B2A, fake_B2A_cam_logit, _ = self.genB2A(real_B)\n",
    "\n",
    "        fake_A2B2A, _, _ = self.genB2A(fake_A2B)\n",
    "        fake_B2A2B, _, _ = self.genA2B(fake_B2A)\n",
    "\n",
    "        fake_A2A, fake_A2A_cam_logit, _ = self.genB2A(real_A)\n",
    "        fake_B2B, fake_B2B_cam_logit, _ = self.genA2B(real_B)\n",
    "\n",
    "        fake_GA_logit, fake_GA_cam_logit, _ = self.disGA(fake_B2A)\n",
    "        fake_LA_logit, fake_LA_cam_logit, _ = self.disLA(fake_B2A)\n",
    "        fake_GB_logit, fake_GB_cam_logit, _ = self.disGB(fake_A2B)\n",
    "        fake_LB_logit, fake_LB_cam_logit, _ = self.disLB(fake_A2B)\n",
    "\n",
    "        G_ad_loss_GA = self.MSE_loss(fake_GA_logit, torch.ones_like(fake_GA_logit).to(self.device))\n",
    "        G_ad_cam_loss_GA = self.MSE_loss(fake_GA_cam_logit, torch.ones_like(fake_GA_cam_logit).to(self.device))\n",
    "        G_ad_loss_LA = self.MSE_loss(fake_LA_logit, torch.ones_like(fake_LA_logit).to(self.device))\n",
    "        G_ad_cam_loss_LA = self.MSE_loss(fake_LA_cam_logit, torch.ones_like(fake_LA_cam_logit).to(self.device))\n",
    "        G_ad_loss_GB = self.MSE_loss(fake_GB_logit, torch.ones_like(fake_GB_logit).to(self.device))\n",
    "        G_ad_cam_loss_GB = self.MSE_loss(fake_GB_cam_logit, torch.ones_like(fake_GB_cam_logit).to(self.device))\n",
    "        G_ad_loss_LB = self.MSE_loss(fake_LB_logit, torch.ones_like(fake_LB_logit).to(self.device))\n",
    "        G_ad_cam_loss_LB = self.MSE_loss(fake_LB_cam_logit, torch.ones_like(fake_LB_cam_logit).to(self.device))\n",
    "\n",
    "        G_recon_loss_A = self.L1_loss(fake_A2B2A, real_A)\n",
    "        G_recon_loss_B = self.L1_loss(fake_B2A2B, real_B)\n",
    "\n",
    "        G_identity_loss_A = self.L1_loss(fake_A2A, real_A)\n",
    "        G_identity_loss_B = self.L1_loss(fake_B2B, real_B)\n",
    "\n",
    "        G_cam_loss_A = self.BCE_loss(fake_B2A_cam_logit, torch.ones_like(fake_B2A_cam_logit).to(self.device)) + self.BCE_loss(fake_A2A_cam_logit, torch.zeros_like(fake_A2A_cam_logit).to(self.device))\n",
    "        G_cam_loss_B = self.BCE_loss(fake_A2B_cam_logit, torch.ones_like(fake_A2B_cam_logit).to(self.device)) + self.BCE_loss(fake_B2B_cam_logit, torch.zeros_like(fake_B2B_cam_logit).to(self.device))\n",
    "\n",
    "        G_loss_A =  self.adv_weight * (G_ad_loss_GA + G_ad_cam_loss_GA + G_ad_loss_LA + G_ad_cam_loss_LA) + self.cycle_weight * G_recon_loss_A + self.identity_weight * G_identity_loss_A + self.cam_weight * G_cam_loss_A\n",
    "        G_loss_B = self.adv_weight * (G_ad_loss_GB + G_ad_cam_loss_GB + G_ad_loss_LB + G_ad_cam_loss_LB) + self.cycle_weight * G_recon_loss_B + self.identity_weight * G_identity_loss_B + self.cam_weight * G_cam_loss_B\n",
    "\n",
    "        Generator_loss = G_loss_A + G_loss_B\n",
    "        Generator_loss.backward()\n",
    "        self.G_optim.step()\n",
    "\n",
    "        # clip parameter of AdaILN and ILN, applied after optimizer step\n",
    "        self.genA2B.apply(self.Rho_clipper)\n",
    "        self.genB2A.apply(self.Rho_clipper)\n",
    "\n",
    "        if step % print_freq == 0:\n",
    "          time_spent = time.time() - start_time\n",
    "          h = time_spent // 3600\n",
    "          m = (time_spent - h * 3600) // 60\n",
    "          s = int(time_spent - h * 3600 - m * 60)\n",
    "          print(\"[{}/{}]\\nD_loss : {:.4f}\\nG_loss: {:.4f}\".format(step, n_steps, Discriminator_loss, Generator_loss))\n",
    "          print(\"Time: {}:{}:{}\".format(h, m, s))\n",
    "\n",
    "          # Summary writing\n",
    "          G_adv_loss_A = (G_ad_loss_GA + G_ad_cam_loss_GA + G_ad_loss_LA + G_ad_cam_loss_LA)\n",
    "          G_adv_loss_B = (G_ad_loss_GB + G_ad_cam_loss_GB + G_ad_loss_LB + G_ad_cam_loss_LB)\n",
    "          # print((\"loss_G_AB: {:.3f}\\nloss_G_AB_GAN: {:.3f}\\nloss_G_AB_identity: {:.3f}\\n\" + \n",
    "          #       \"loss_G_AB_cycle: {:.3f}\\nloss_G_AB_cam: {:.3f}\\nloss_G_BA: {:.3f}\\nloss_G_BA_GAN: {:.3f}\\n\" + \n",
    "          #       \"loss_G_BA_identity: {:.3f}\\nloss_G_BA_cycle: {:.3f}\\nloss_G_BA_cam: {:.3f}\\n\").format(\n",
    "          #           G_loss_B, G_adv_loss_B, G_identity_loss_B, G_recon_loss_B, G_cam_loss_B, \n",
    "          #           G_loss_A, G_adv_loss_A, G_identity_loss_A, G_recon_loss_A, G_cam_loss_A\n",
    "          #       ))\n",
    "          self.writer.add_scalar('G/G_AB', G_loss_B, global_step=step)\n",
    "          self.writer.add_scalar('G/G_AB_GAN', G_adv_loss_B, global_step=step)\n",
    "          self.writer.add_scalar('G/G_AB_GAN_G', G_ad_loss_GB, global_step=step)\n",
    "          self.writer.add_scalar('G/G_AB_GAN_L', G_ad_loss_LB, global_step=step)\n",
    "\n",
    "          self.writer.add_scalar('G/G_AB_cam', G_cam_loss_B, global_step=step)\n",
    "          self.writer.add_scalar('G/G_AB_identity', G_identity_loss_B, global_step=step)\n",
    "          self.writer.add_scalar('G/G_AB_cycle', G_recon_loss_B, global_step=step)\n",
    "          \n",
    "\n",
    "          self.writer.add_scalar('G/G_BA', G_loss_A, global_step=step)\n",
    "          self.writer.add_scalar('G/G_BA_GAN', G_adv_loss_A, global_step=step)\n",
    "          self.writer.add_scalar('G/G_BA_GAN_G', G_ad_loss_GA, global_step=step)\n",
    "          self.writer.add_scalar('G/G_BA_GAN_L', G_ad_loss_LA, global_step=step)\n",
    "\n",
    "          self.writer.add_scalar('G/G_BA_cam', G_cam_loss_A, global_step=step)\n",
    "          self.writer.add_scalar('G/G_BA_identity', G_identity_loss_A, global_step=step)\n",
    "          self.writer.add_scalar('G/G_BA_cycle', G_recon_loss_A, global_step=step)\n",
    "          \n",
    "\n",
    "          # Discriminator monitoring\n",
    "          D_LA = D_ad_loss_LA + D_ad_cam_loss_LA\n",
    "          D_GA = D_ad_loss_GA + D_ad_cam_loss_GA\n",
    "          \n",
    "          D_LB = D_ad_loss_LB + D_ad_cam_loss_LB\n",
    "          D_GB = D_ad_loss_GB + D_ad_cam_loss_GB\n",
    "          # print((\"loss_D_LA: {:.3f}\\nloss_D_LA_GAN: {:.3f}\\nloss_D_LA_cam: {:.3f}\\n\" + \n",
    "          #       \"loss_D_GA: {:.3f}\\nloss_D_GA_GAN: {:.3f}\\nloss_D_GA_cam: {:.3f}\\n\" + \n",
    "          #       \"loss_D_LB: {:.3f}\\nloss_D_LB_GAN: {:.3f}\\nloss_D_LB_cam: {:.3f}\\n\" +\n",
    "          #       \"loss_D_GB: {:.3f}\\nloss_D_GB_GAN: {:.3f}\\nloss_D_GB_cam: {:.3f}\\n\").format(\n",
    "          #           D_LA, D_ad_loss_LA, D_ad_cam_loss_LA, D_GA, D_ad_loss_GA, D_ad_cam_loss_GA,\n",
    "          #           D_LB, D_ad_loss_LB, D_ad_cam_loss_LB, D_GB, D_ad_loss_GB, D_ad_cam_loss_GB\n",
    "          #       ))\n",
    "          self.writer.add_scalar(\"D/D_LA\", D_LA, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_LA_GAN\", D_ad_loss_LA, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_LA_cam\", D_ad_cam_loss_LA, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_GA\", D_GA, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_GA_GAN\", D_ad_loss_GA, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_GA_cam\", D_ad_cam_loss_GA, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_LB\", D_LB, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_LB_GAN\", D_ad_loss_LB, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_LB_cam\", D_ad_cam_loss_LB, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_GB\", D_GB, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_GB_GAN\", D_ad_loss_GB, global_step=step)\n",
    "          self.writer.add_scalar(\"D/D_GB_cam\", D_ad_cam_loss_GB, global_step=step)\n",
    "          \n",
    "        if step % save_freq == 0:\n",
    "          print(\"Save the checkpoint : \", step)\n",
    "          self.save(checkpoint_dir, step)\n",
    "\n",
    "        if step % test_freq == 0:\n",
    "        # copied from original implementation\n",
    "          train_sample_num = 5\n",
    "\n",
    "          A2B = np.zeros((image_size * 4, 0, 3))\n",
    "          B2A = np.zeros((image_size * 4, 0, 3))\n",
    "\n",
    "          self.genA2B.eval(), self.genB2A.eval(), self.disGA.eval(), self.disGB.eval(), self.disLA.eval(), self.disLB.eval()\n",
    "          \n",
    "          for _ in range(train_sample_num):\n",
    "            try:\n",
    "                real_A = trainA_iter.next()\n",
    "            except:\n",
    "                trainA_iter = iter(self.trainA_loader)\n",
    "                real_A = trainA_iter.next()\n",
    "\n",
    "            try:\n",
    "                real_B = trainB_iter.next()\n",
    "            except:\n",
    "                trainB_iter = iter(self.trainB_loader)\n",
    "                real_B = trainB_iter.next()\n",
    "            real_A, real_B = real_A.to(device), real_B.to(device)\n",
    "\n",
    "            fake_A2B, _, fake_A2B_heatmap = self.genA2B(real_A)\n",
    "            fake_B2A, _, fake_B2A_heatmap = self.genB2A(real_B)\n",
    "\n",
    "            fake_A2B2A, _, fake_A2B2A_heatmap = self.genB2A(fake_A2B)\n",
    "            fake_B2A2B, _, fake_B2A2B_heatmap = self.genA2B(fake_B2A)\n",
    "\n",
    "            fake_A2A, _, fake_A2A_heatmap = self.genB2A(real_A)\n",
    "            fake_B2B, _, fake_B2B_heatmap = self.genA2B(real_B)\n",
    "\n",
    "            A2B = np.concatenate((A2B, np.concatenate((RGB2BGR(tensor2numpy(denorm(real_A[0]))),\n",
    "                                                        cam(tensor2numpy(fake_A2B_heatmap[0]), image_size),\n",
    "                                                        RGB2BGR(tensor2numpy(denorm(fake_A2B[0]))),\n",
    "                                                        RGB2BGR(tensor2numpy(denorm(fake_A2B2A[0])))), 0)), 1)\n",
    "\n",
    "            B2A = np.concatenate((B2A, np.concatenate((RGB2BGR(tensor2numpy(denorm(real_B[0]))),\n",
    "                                                        cam(tensor2numpy(fake_B2A_heatmap[0]), image_size),\n",
    "                                                        RGB2BGR(tensor2numpy(denorm(fake_B2A[0]))),\n",
    "                                                        RGB2BGR(tensor2numpy(denorm(fake_B2A2B[0])))), 0)), 1)\n",
    "          cv2.imwrite(os.path.join(images_dir,'A2B_%07d.png' % step), A2B * 255.0)\n",
    "          cv2.imwrite(os.path.join(images_dir,'B2A_%07d.png' % step), B2A * 255.0)\n",
    "          self.genA2B.train(), self.genB2A.train(), self.disLA.train(), self.disLB.train(), self.disGA.train(), self.disGB.train()\n",
    "        counter += 1\n",
    "    except Exception as e:\n",
    "      raise e\n",
    "    finally:\n",
    "      print(\"---- Save the checkpoint ----\")\n",
    "      self.save(checkpoint_dir, counter)\n",
    "      print(\"---- Finished ----\".upper())\n",
    "\n",
    "\n",
    "\n",
    "  def load(self, path, step):\n",
    "    params = torch.load(os.path.join(path, 'params_{}.pt'.format(step)))\n",
    "    self.genA2B.load_state_dict(params['genA2B'])\n",
    "    self.genB2A.load_state_dict(params['genB2A'])\n",
    "    self.disGA.load_state_dict(params['disGA'])\n",
    "    self.disGB.load_state_dict(params['disGB'])\n",
    "    self.disLA.load_state_dict(params['disLA'])\n",
    "    self.disLB.load_state_dict(params['disLB'])\n",
    "\n",
    "  def save(self, path, step):\n",
    "    params = {}\n",
    "    params['genA2B'] = self.genA2B.state_dict()\n",
    "    params['genB2A'] = self.genB2A.state_dict()\n",
    "    params['disGA'] = self.disGA.state_dict()\n",
    "    params['disGB'] = self.disGB.state_dict()\n",
    "    params['disLA'] = self.disLA.state_dict()\n",
    "    params['disLB'] = self.disLB.state_dict()\n",
    "    torch.save(params, os.path.join(path, 'params_{}.pt'.format(step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42905,
     "status": "ok",
     "timestamp": 1581898521552,
     "user": {
      "displayName": "Владислав Андроник",
      "photoUrl": "",
      "userId": "15929840215236502543"
     },
     "user_tz": -120
    },
    "id": "Hy7jer4JtiWW",
    "outputId": "2550e3a5-556a-46e2-dc3d-9eda0db5a79d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = UGATIT()\n",
    "model.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e795d79c599149fca199096cc615f064",
      "ab4178ad97f74e408630d31032b25dcc",
      "416bb5cb6af24451b69c4100819417bf",
      "0d3f2d40f06246c6a69c7ddc3de8416e",
      "74a1132a999f4683b5a7e7612208b082",
      "77f82b73ebd745d9a5edfa194a86f5a9",
      "f8f22c14d1a04d5c951e3f7da454b2e2",
      "206d869225fe48358d1b882fe708963c"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10758050,
     "status": "error",
     "timestamp": 1581892117015,
     "user": {
      "displayName": "Владислав Андроник",
      "photoUrl": "",
      "userId": "15929840215236502543"
     },
     "user_tz": -120
    },
    "id": "xutHcTMqtnml",
    "outputId": "a7bef264-c608-4582-fa30-be655ecc2cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- LOADING THE MODEL ----\n",
      "Load the model from 202812\n",
      "training start !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e795d79c599149fca199096cc615f064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=97187), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202820/300000]\n",
      "D_loss : 2.7029\n",
      "G_loss: 38.3516\n",
      "Time: 0.0:0.0:22\n",
      "[202830/300000]\n",
      "D_loss : 4.3729\n",
      "G_loss: 36.5247\n",
      "Time: 0.0:0.0:51\n",
      "[202840/300000]\n",
      "D_loss : 2.8359\n",
      "G_loss: 199.9508\n",
      "Time: 0.0:1.0:18\n",
      "[202850/300000]\n",
      "D_loss : 3.7279\n",
      "G_loss: 15.3122\n",
      "Time: 0.0:1.0:46\n",
      "[202860/300000]\n",
      "D_loss : 2.7251\n",
      "G_loss: 60.3993\n",
      "Time: 0.0:2.0:14\n",
      "[202870/300000]\n",
      "D_loss : 3.0178\n",
      "G_loss: 80.7227\n",
      "Time: 0.0:2.0:42\n",
      "[202880/300000]\n",
      "D_loss : 3.2867\n",
      "G_loss: 22.4799\n",
      "Time: 0.0:3.0:9\n",
      "[202890/300000]\n",
      "D_loss : 4.1026\n",
      "G_loss: 6.7981\n",
      "Time: 0.0:3.0:37\n",
      "[202900/300000]\n",
      "D_loss : 2.7915\n",
      "G_loss: 149.2331\n",
      "Time: 0.0:4.0:4\n",
      "[202910/300000]\n",
      "D_loss : 2.4568\n",
      "G_loss: 144.5227\n",
      "Time: 0.0:4.0:55\n",
      "[202920/300000]\n",
      "D_loss : 4.0195\n",
      "G_loss: 16.5303\n",
      "Time: 0.0:5.0:23\n",
      "[202930/300000]\n",
      "D_loss : 2.3714\n",
      "G_loss: 28.6949\n",
      "Time: 0.0:5.0:51\n",
      "[202940/300000]\n",
      "D_loss : 2.1401\n",
      "G_loss: 10.8650\n",
      "Time: 0.0:6.0:20\n",
      "[202950/300000]\n",
      "D_loss : 4.3576\n",
      "G_loss: 311.3488\n",
      "Time: 0.0:6.0:47\n",
      "[202960/300000]\n",
      "D_loss : 4.5807\n",
      "G_loss: 285.7956\n",
      "Time: 0.0:7.0:14\n",
      "[202970/300000]\n",
      "D_loss : 3.3299\n",
      "G_loss: 195.9853\n",
      "Time: 0.0:7.0:41\n",
      "[202980/300000]\n",
      "D_loss : 3.5155\n",
      "G_loss: 36.8275\n",
      "Time: 0.0:8.0:9\n",
      "[202990/300000]\n",
      "D_loss : 2.3902\n",
      "G_loss: 34.6647\n",
      "Time: 0.0:8.0:36\n",
      "[203000/300000]\n",
      "D_loss : 4.2030\n",
      "G_loss: 499.1905\n",
      "Time: 0.0:9.0:4\n",
      "[203010/300000]\n",
      "D_loss : 3.0717\n",
      "G_loss: 479.5700\n",
      "Time: 0.0:9.0:40\n",
      "[203020/300000]\n",
      "D_loss : 2.5041\n",
      "G_loss: 143.4960\n",
      "Time: 0.0:10.0:7\n",
      "[203030/300000]\n",
      "D_loss : 2.6284\n",
      "G_loss: 82.7403\n",
      "Time: 0.0:10.0:35\n",
      "[203040/300000]\n",
      "D_loss : 3.4685\n",
      "G_loss: 42.5132\n",
      "Time: 0.0:11.0:1\n",
      "[203050/300000]\n",
      "D_loss : 2.9365\n",
      "G_loss: 23.2333\n",
      "Time: 0.0:11.0:28\n",
      "[203060/300000]\n",
      "D_loss : 3.8108\n",
      "G_loss: 29.7368\n",
      "Time: 0.0:11.0:55\n",
      "[203070/300000]\n",
      "D_loss : 2.9157\n",
      "G_loss: 7.3628\n",
      "Time: 0.0:12.0:23\n",
      "[203080/300000]\n",
      "D_loss : 2.7278\n",
      "G_loss: 17.5112\n",
      "Time: 0.0:12.0:50\n",
      "[203090/300000]\n",
      "D_loss : 3.3214\n",
      "G_loss: 349.9391\n",
      "Time: 0.0:13.0:17\n",
      "[203100/300000]\n",
      "D_loss : 2.6162\n",
      "G_loss: 50.9164\n",
      "Time: 0.0:13.0:45\n",
      "[203110/300000]\n",
      "D_loss : 3.7603\n",
      "G_loss: 17.5667\n",
      "Time: 0.0:14.0:20\n",
      "[203120/300000]\n",
      "D_loss : 2.6209\n",
      "G_loss: 197.3078\n",
      "Time: 0.0:14.0:47\n",
      "[203130/300000]\n",
      "D_loss : 2.8492\n",
      "G_loss: 12.7902\n",
      "Time: 0.0:15.0:17\n",
      "[203140/300000]\n",
      "D_loss : 2.5534\n",
      "G_loss: 34.3818\n",
      "Time: 0.0:15.0:45\n",
      "[203150/300000]\n",
      "D_loss : 2.5801\n",
      "G_loss: 15.3266\n",
      "Time: 0.0:16.0:12\n",
      "[203160/300000]\n",
      "D_loss : 3.3375\n",
      "G_loss: 577.9257\n",
      "Time: 0.0:16.0:40\n",
      "[203170/300000]\n",
      "D_loss : 3.2409\n",
      "G_loss: 55.7779\n",
      "Time: 0.0:17.0:7\n",
      "[203180/300000]\n",
      "D_loss : 3.7965\n",
      "G_loss: 104.8763\n",
      "Time: 0.0:17.0:35\n",
      "[203190/300000]\n",
      "D_loss : 4.1950\n",
      "G_loss: 17.0774\n",
      "Time: 0.0:18.0:3\n",
      "[203200/300000]\n",
      "D_loss : 3.0085\n",
      "G_loss: 22.5049\n",
      "Time: 0.0:18.0:30\n",
      "[203210/300000]\n",
      "D_loss : 3.8069\n",
      "G_loss: 79.6394\n",
      "Time: 0.0:19.0:5\n",
      "[203220/300000]\n",
      "D_loss : 3.9672\n",
      "G_loss: 39.2978\n",
      "Time: 0.0:19.0:35\n",
      "[203230/300000]\n",
      "D_loss : 2.1415\n",
      "G_loss: 13.8813\n",
      "Time: 0.0:20.0:3\n",
      "[203240/300000]\n",
      "D_loss : 3.8097\n",
      "G_loss: 512.2242\n",
      "Time: 0.0:20.0:31\n",
      "[203250/300000]\n",
      "D_loss : 3.5246\n",
      "G_loss: 271.9148\n",
      "Time: 0.0:20.0:59\n",
      "[203260/300000]\n",
      "D_loss : 2.8702\n",
      "G_loss: 9.9751\n",
      "Time: 0.0:21.0:26\n",
      "[203270/300000]\n",
      "D_loss : 3.3140\n",
      "G_loss: 49.0097\n",
      "Time: 0.0:21.0:54\n",
      "[203280/300000]\n",
      "D_loss : 3.4098\n",
      "G_loss: 317.8505\n",
      "Time: 0.0:22.0:21\n",
      "[203290/300000]\n",
      "D_loss : 2.8071\n",
      "G_loss: 15.0245\n",
      "Time: 0.0:22.0:48\n",
      "[203300/300000]\n",
      "D_loss : 4.2475\n",
      "G_loss: 134.2491\n",
      "Time: 0.0:23.0:16\n",
      "[203310/300000]\n",
      "D_loss : 2.1844\n",
      "G_loss: 104.0608\n",
      "Time: 0.0:23.0:51\n",
      "[203320/300000]\n",
      "D_loss : 2.4257\n",
      "G_loss: 17.6403\n",
      "Time: 0.0:24.0:19\n",
      "[203330/300000]\n",
      "D_loss : 2.8223\n",
      "G_loss: 14.9586\n",
      "Time: 0.0:24.0:47\n",
      "[203340/300000]\n",
      "D_loss : 3.2267\n",
      "G_loss: 47.1299\n",
      "Time: 0.0:25.0:15\n",
      "[203350/300000]\n",
      "D_loss : 3.2646\n",
      "G_loss: 145.5392\n",
      "Time: 0.0:25.0:42\n",
      "[203360/300000]\n",
      "D_loss : 2.2154\n",
      "G_loss: 275.9908\n",
      "Time: 0.0:26.0:9\n",
      "[203370/300000]\n",
      "D_loss : 2.7763\n",
      "G_loss: 19.1155\n",
      "Time: 0.0:26.0:37\n",
      "[203380/300000]\n",
      "D_loss : 2.2318\n",
      "G_loss: 18.7709\n",
      "Time: 0.0:27.0:4\n",
      "[203390/300000]\n",
      "D_loss : 3.1915\n",
      "G_loss: 16.8192\n",
      "Time: 0.0:27.0:31\n",
      "[203400/300000]\n",
      "D_loss : 2.8164\n",
      "G_loss: 26.5563\n",
      "Time: 0.0:28.0:1\n",
      "[203410/300000]\n",
      "D_loss : 2.6541\n",
      "G_loss: 61.3203\n",
      "Time: 0.0:28.0:36\n",
      "[203420/300000]\n",
      "D_loss : 2.5424\n",
      "G_loss: 306.9895\n",
      "Time: 0.0:29.0:4\n",
      "[203430/300000]\n",
      "D_loss : 2.3809\n",
      "G_loss: 10.8116\n",
      "Time: 0.0:29.0:32\n",
      "[203440/300000]\n",
      "D_loss : 3.2773\n",
      "G_loss: 345.6970\n",
      "Time: 0.0:29.0:59\n",
      "[203450/300000]\n",
      "D_loss : 4.1051\n",
      "G_loss: 43.9917\n",
      "Time: 0.0:30.0:25\n",
      "[203460/300000]\n",
      "D_loss : 3.2483\n",
      "G_loss: 8.4195\n",
      "Time: 0.0:30.0:53\n",
      "[203470/300000]\n",
      "D_loss : 2.9473\n",
      "G_loss: 40.8258\n",
      "Time: 0.0:31.0:21\n",
      "[203480/300000]\n",
      "D_loss : 2.6369\n",
      "G_loss: 200.1530\n",
      "Time: 0.0:31.0:48\n",
      "[203490/300000]\n",
      "D_loss : 2.7702\n",
      "G_loss: 266.2963\n",
      "Time: 0.0:32.0:20\n",
      "[203500/300000]\n",
      "D_loss : 3.6050\n",
      "G_loss: 15.6823\n",
      "Time: 0.0:32.0:47\n",
      "[203510/300000]\n",
      "D_loss : 1.9546\n",
      "G_loss: 10.2387\n",
      "Time: 0.0:33.0:22\n",
      "[203520/300000]\n",
      "D_loss : 2.9554\n",
      "G_loss: 179.6786\n",
      "Time: 0.0:33.0:49\n",
      "[203530/300000]\n",
      "D_loss : 2.8341\n",
      "G_loss: 9.3911\n",
      "Time: 0.0:34.0:16\n",
      "[203540/300000]\n",
      "D_loss : 3.2640\n",
      "G_loss: 36.8170\n",
      "Time: 0.0:34.0:43\n",
      "[203550/300000]\n",
      "D_loss : 2.6069\n",
      "G_loss: 8.3331\n",
      "Time: 0.0:35.0:12\n",
      "[203560/300000]\n",
      "D_loss : 3.3068\n",
      "G_loss: 66.4312\n",
      "Time: 0.0:35.0:40\n",
      "[203570/300000]\n",
      "D_loss : 3.3526\n",
      "G_loss: 25.3826\n",
      "Time: 0.0:36.0:10\n",
      "[203580/300000]\n",
      "D_loss : 3.3458\n",
      "G_loss: 41.6070\n",
      "Time: 0.0:36.0:38\n",
      "[203590/300000]\n",
      "D_loss : 2.6894\n",
      "G_loss: 19.0899\n",
      "Time: 0.0:37.0:5\n",
      "[203600/300000]\n",
      "D_loss : 2.9117\n",
      "G_loss: 79.8159\n",
      "Time: 0.0:37.0:34\n",
      "[203610/300000]\n",
      "D_loss : 3.2984\n",
      "G_loss: 10.6589\n",
      "Time: 0.0:38.0:10\n",
      "[203620/300000]\n",
      "D_loss : 3.2725\n",
      "G_loss: 50.3651\n",
      "Time: 0.0:38.0:37\n",
      "[203630/300000]\n",
      "D_loss : 1.6534\n",
      "G_loss: 20.3470\n",
      "Time: 0.0:39.0:4\n",
      "[203640/300000]\n",
      "D_loss : 3.7709\n",
      "G_loss: 74.9829\n",
      "Time: 0.0:39.0:32\n",
      "[203650/300000]\n",
      "D_loss : 2.7600\n",
      "G_loss: 93.1092\n",
      "Time: 0.0:39.0:59\n",
      "[203660/300000]\n",
      "D_loss : 3.7430\n",
      "G_loss: 171.1630\n",
      "Time: 0.0:40.0:27\n",
      "[203670/300000]\n",
      "D_loss : 2.5956\n",
      "G_loss: 19.6122\n",
      "Time: 0.0:40.0:55\n",
      "[203680/300000]\n",
      "D_loss : 2.9846\n",
      "G_loss: 35.3401\n",
      "Time: 0.0:41.0:23\n",
      "[203690/300000]\n",
      "D_loss : 2.5762\n",
      "G_loss: 58.9452\n",
      "Time: 0.0:41.0:50\n",
      "[203700/300000]\n",
      "D_loss : 2.5781\n",
      "G_loss: 13.5721\n",
      "Time: 0.0:42.0:17\n",
      "[203710/300000]\n",
      "D_loss : 3.2984\n",
      "G_loss: 28.8899\n",
      "Time: 0.0:42.0:52\n",
      "[203720/300000]\n",
      "D_loss : 2.3454\n",
      "G_loss: 54.6092\n",
      "Time: 0.0:43.0:20\n",
      "[203730/300000]\n",
      "D_loss : 3.7882\n",
      "G_loss: 9.7063\n",
      "Time: 0.0:43.0:56\n",
      "[203740/300000]\n",
      "D_loss : 2.3928\n",
      "G_loss: 51.2536\n",
      "Time: 0.0:44.0:23\n",
      "[203750/300000]\n",
      "D_loss : 4.4090\n",
      "G_loss: 186.5499\n",
      "Time: 0.0:44.0:50\n",
      "[203760/300000]\n",
      "D_loss : 2.8773\n",
      "G_loss: 448.6993\n",
      "Time: 0.0:45.0:17\n",
      "[203770/300000]\n",
      "D_loss : 2.2792\n",
      "G_loss: 380.7156\n",
      "Time: 0.0:45.0:45\n",
      "[203780/300000]\n",
      "D_loss : 2.8511\n",
      "G_loss: 61.1007\n",
      "Time: 0.0:46.0:12\n",
      "[203790/300000]\n",
      "D_loss : 2.0776\n",
      "G_loss: 16.4608\n",
      "Time: 0.0:46.0:40\n",
      "[203800/300000]\n",
      "D_loss : 3.2455\n",
      "G_loss: 34.0302\n",
      "Time: 0.0:47.0:7\n",
      "[203810/300000]\n",
      "D_loss : 2.7470\n",
      "G_loss: 195.1205\n",
      "Time: 0.0:47.0:42\n",
      "[203820/300000]\n",
      "D_loss : 3.6362\n",
      "G_loss: 78.1504\n",
      "Time: 0.0:48.0:13\n",
      "[203830/300000]\n",
      "D_loss : 2.4660\n",
      "G_loss: 308.2803\n",
      "Time: 0.0:48.0:40\n",
      "[203840/300000]\n",
      "D_loss : 2.6141\n",
      "G_loss: 25.1621\n",
      "Time: 0.0:49.0:7\n",
      "[203850/300000]\n",
      "D_loss : 1.7306\n",
      "G_loss: 11.4898\n",
      "Time: 0.0:49.0:36\n",
      "[203860/300000]\n",
      "D_loss : 2.0943\n",
      "G_loss: 131.9538\n",
      "Time: 0.0:50.0:3\n",
      "[203870/300000]\n",
      "D_loss : 2.7362\n",
      "G_loss: 27.0759\n",
      "Time: 0.0:50.0:31\n",
      "[203880/300000]\n",
      "D_loss : 2.6344\n",
      "G_loss: 12.6521\n",
      "Time: 0.0:50.0:59\n",
      "[203890/300000]\n",
      "D_loss : 2.3162\n",
      "G_loss: 12.0114\n",
      "Time: 0.0:51.0:25\n",
      "[203900/300000]\n",
      "D_loss : 3.6947\n",
      "G_loss: 96.7174\n",
      "Time: 0.0:51.0:54\n",
      "[203910/300000]\n",
      "D_loss : 2.4497\n",
      "G_loss: 10.3423\n",
      "Time: 0.0:52.0:30\n",
      "[203920/300000]\n",
      "D_loss : 2.7135\n",
      "G_loss: 12.2464\n",
      "Time: 0.0:53.0:2\n",
      "[203930/300000]\n",
      "D_loss : 1.9983\n",
      "G_loss: 78.5166\n",
      "Time: 0.0:53.0:29\n",
      "[203940/300000]\n",
      "D_loss : 2.6642\n",
      "G_loss: 7.2937\n",
      "Time: 0.0:53.0:57\n",
      "[203950/300000]\n",
      "D_loss : 4.2297\n",
      "G_loss: 9.7479\n",
      "Time: 0.0:54.0:24\n",
      "[203960/300000]\n",
      "D_loss : 2.7499\n",
      "G_loss: 37.5538\n",
      "Time: 0.0:54.0:51\n",
      "[203970/300000]\n",
      "D_loss : 2.7518\n",
      "G_loss: 15.6971\n",
      "Time: 0.0:55.0:19\n",
      "[203980/300000]\n",
      "D_loss : 3.0996\n",
      "G_loss: 67.6224\n",
      "Time: 0.0:55.0:47\n",
      "[203990/300000]\n",
      "D_loss : 3.5288\n",
      "G_loss: 166.1328\n",
      "Time: 0.0:56.0:14\n",
      "[204000/300000]\n",
      "D_loss : 2.7305\n",
      "G_loss: 14.6080\n",
      "Time: 0.0:56.0:42\n",
      "[204010/300000]\n",
      "D_loss : 2.7934\n",
      "G_loss: 53.9684\n",
      "Time: 0.0:57.0:17\n",
      "[204020/300000]\n",
      "D_loss : 4.0509\n",
      "G_loss: 66.1101\n",
      "Time: 0.0:57.0:46\n",
      "[204030/300000]\n",
      "D_loss : 3.9142\n",
      "G_loss: 81.0016\n",
      "Time: 0.0:58.0:13\n",
      "[204040/300000]\n",
      "D_loss : 4.6909\n",
      "G_loss: 1891.8578\n",
      "Time: 0.0:58.0:40\n",
      "[204050/300000]\n",
      "D_loss : 2.9218\n",
      "G_loss: 215.5335\n",
      "Time: 0.0:59.0:8\n",
      "[204060/300000]\n",
      "D_loss : 2.8154\n",
      "G_loss: 21.0226\n",
      "Time: 0.0:59.0:34\n",
      "[204070/300000]\n",
      "D_loss : 4.0105\n",
      "G_loss: 121.6875\n",
      "Time: 1.0:0.0:6\n",
      "[204080/300000]\n",
      "D_loss : 4.4331\n",
      "G_loss: 10.6496\n",
      "Time: 1.0:0.0:34\n",
      "[204090/300000]\n",
      "D_loss : 2.3177\n",
      "G_loss: 19.4270\n",
      "Time: 1.0:1.0:6\n",
      "[204100/300000]\n",
      "D_loss : 2.5893\n",
      "G_loss: 114.5822\n",
      "Time: 1.0:1.0:34\n",
      "[204110/300000]\n",
      "D_loss : 2.9968\n",
      "G_loss: 16.2678\n",
      "Time: 1.0:2.0:8\n",
      "[204120/300000]\n",
      "D_loss : 4.0519\n",
      "G_loss: 21.7324\n",
      "Time: 1.0:2.0:35\n",
      "[204130/300000]\n",
      "D_loss : 3.8903\n",
      "G_loss: 265.6987\n",
      "Time: 1.0:3.0:3\n",
      "[204140/300000]\n",
      "D_loss : 2.0776\n",
      "G_loss: 318.6238\n",
      "Time: 1.0:3.0:30\n",
      "[204150/300000]\n",
      "D_loss : 2.2052\n",
      "G_loss: 9.1196\n",
      "Time: 1.0:3.0:57\n",
      "[204160/300000]\n",
      "D_loss : 3.1973\n",
      "G_loss: 9.5821\n",
      "Time: 1.0:4.0:25\n",
      "[204170/300000]\n",
      "D_loss : 4.6994\n",
      "G_loss: 2385.9709\n",
      "Time: 1.0:4.0:52\n",
      "[204180/300000]\n",
      "D_loss : 3.3997\n",
      "G_loss: 285.7932\n",
      "Time: 1.0:5.0:19\n",
      "[204190/300000]\n",
      "D_loss : 3.4776\n",
      "G_loss: 126.3457\n",
      "Time: 1.0:5.0:47\n",
      "[204200/300000]\n",
      "D_loss : 2.5282\n",
      "G_loss: 326.8868\n",
      "Time: 1.0:6.0:14\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GvT4A2jIt6IX"
   },
   "outputs": [],
   "source": [
    "# function to prevent google colab from sleeping\n",
    "\"\"\"\n",
    "function preventFromOff(){\n",
    "  console.log(\"Click button\");\n",
    "  document.querySelector(\"colab-toolbar-button#connect\").click() \n",
    "}\n",
    "var timeout = 8 * 60 * 60 * 1000;\n",
    "var delay = 3 * 60 * 1000;\n",
    "var refreshId = setInterval(preventFromOff, delay);\n",
    "setTimeout(() => {clearInterval(refreshId); console.log(\"Stopped script\");}, timeout);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YWs2xGfHiMNR"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wwBoQe6KiRCt"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir=ugatit/output/summary/summary_v0.1.0/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNO69YDourIwnAFpgEAPK3p",
   "name": "ugait_v0.1.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d3f2d40f06246c6a69c7ddc3de8416e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_206d869225fe48358d1b882fe708963c",
      "placeholder": "​",
      "style": "IPY_MODEL_f8f22c14d1a04d5c951e3f7da454b2e2",
      "value": "  1% 1387/97187 [1:06:11&lt;72:42:00,  2.73s/it]"
     }
    },
    "206d869225fe48358d1b882fe708963c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "416bb5cb6af24451b69c4100819417bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77f82b73ebd745d9a5edfa194a86f5a9",
      "max": 97187,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74a1132a999f4683b5a7e7612208b082",
      "value": 1387
     }
    },
    "74a1132a999f4683b5a7e7612208b082": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77f82b73ebd745d9a5edfa194a86f5a9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab4178ad97f74e408630d31032b25dcc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e795d79c599149fca199096cc615f064": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_416bb5cb6af24451b69c4100819417bf",
       "IPY_MODEL_0d3f2d40f06246c6a69c7ddc3de8416e"
      ],
      "layout": "IPY_MODEL_ab4178ad97f74e408630d31032b25dcc"
     }
    },
    "f8f22c14d1a04d5c951e3f7da454b2e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
