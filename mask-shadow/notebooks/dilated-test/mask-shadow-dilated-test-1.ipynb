{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mask-shadow-dilated-test-1.ipynb","provenance":[],"collapsed_sections":["ih5jjEJIGPwI","NRZ9EoJlwsnM"],"authorship_tag":"ABX9TyORSnwtQlDB7B7CLb7LXBB2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TubX68DLtATS","colab_type":"text"},"source":["### Tuning dilation rates\n","1. Current\n","  - A2B - [1,1,1,1,1,2,2,4,8]. [181,301]\n","  - B2A - [1,1,1,1,1,2,2,4,8]. [181,301]\n","2. Alternative\n","  - A2B - [1,1,1,1,1,2,2,4,8]. [181,301]\n","  - B2A - [ones]. [85,205]"]},{"cell_type":"code","metadata":{"id":"mAZqJs1rNJqk","colab_type":"code","outputId":"a342f193-11b0-4cff-87bf-09fd4415bf0d","executionInfo":{"status":"ok","timestamp":1584753270853,"user_tz":-120,"elapsed":34360,"user":{"displayName":"Владислав Андроник","photoUrl":"","userId":"15929840215236502543"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive/')\n","path_basic = 'drive/My Drive/gan_experiments'\n","os.chdir(path_basic)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MYfHqjw2EO6Z","colab_type":"code","colab":{}},"source":["import torch\n","from torch.nn import init\n","from torch import nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader,Dataset\n","from torch.autograd import Variable\n","from torch.utils.tensorboard import SummaryWriter \n","\n","from skimage.filters import threshold_otsu\n","from PIL import Image\n","import functools\n","import itertools\n","import numpy as np\n","import random\n","\n","import h5py\n","\n","import os\n","import sys\n","import glob\n","from tqdm import tqdm_notebook\n","import re\n","\n","import matplotlib.pyplot as plt\n","import pickle\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9eU38c1glQDp","colab_type":"text"},"source":["### Additional modules implementation"]},{"cell_type":"code","metadata":{"id":"Tbal9TpD3K2i","colab_type":"code","colab":{}},"source":["# timer utils\n","import time\n","import functools\n","def timer(f):\n","  @functools.wraps(f)\n","  def wrapper(*args, **kwargs):\n","    start_time = time.time()\n","    r = f(*args, **kwargs)\n","    duration = time.time() - start_time\n","    result = {\n","        'result':r,\n","        'time':duration\n","    }\n","    return result\n","  return wrapper"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"llViHAJ2EPEn","colab_type":"text"},"source":["### Blocks"]},{"cell_type":"code","metadata":{"id":"hM7rtwdjEPAO","colab_type":"code","colab":{}},"source":["class ResidualBlock(nn.Module):\n","    \"\"\"\n","      SEDResidualBlock\n","      Parameters:\n","        dilation_factor -- dilated convolution hyperparam\n","        r -- reduction factor for SE bottleneck\n","    \"\"\"\n","    def __init__(self, in_features, dilation_factor, r=4):\n","        super(ResidualBlock, self).__init__()\n","        k = 3\n","        d = dilation_factor\n","        pad = int(((k - 1) * (d - 1) + k - 1) / 2)\n","\n","        conv_block = [  nn.ReflectionPad2d(pad),\n","                        nn.utils.spectral_norm(nn.Conv2d(in_features, in_features, 3, dilation=d)),\n","                        nn.InstanceNorm2d(in_features),\n","                        nn.ReLU(inplace=True),\n","                      \n","                        nn.ReflectionPad2d(pad),\n","                        nn.utils.spectral_norm(nn.Conv2d(in_features, in_features, 3, dilation=d)),\n","                        nn.InstanceNorm2d(in_features)\n","                      ]\n","\n","        self.conv_block = nn.Sequential(*conv_block)\n","\n","    def forward(self, x):\n","        return x + self.conv_block(x)\n","\n","\n","class Generator_S2F(nn.Module):\n","\n","    \"\"\"reduction -- reduction factor for SE bottleneck\"\"\"\n","    def __init__(self, input_nc, output_nc, n_residual_blocks=9,\n","                 dilation_factors=[1,1,1,2,4,8,16,1,1],\n","                 reduction=4):\n","        super(Generator_S2F, self).__init__()\n","        assert len(dilation_factors) == n_residual_blocks\n","\n","        # Initial convolution block\n","        model = [   nn.ReflectionPad2d(3),\n","                    nn.utils.spectral_norm(nn.Conv2d(input_nc, 64, 7)),\n","                    nn.InstanceNorm2d(64),\n","                    nn.ReLU(inplace=True) ]\n","\n","        # Downsampling\n","        in_features = 64\n","        out_features = in_features*2\n","        for _ in range(2):\n","            model += [  nn.utils.spectral_norm(nn.Conv2d(in_features, out_features, 3, stride=2, padding=1)),\n","                        nn.InstanceNorm2d(out_features),\n","                        nn.ReLU(inplace=True) ]\n","            in_features = out_features\n","            out_features = in_features*2\n","\n","        # Residual blocks\n","        # Paste self-attention modules before dilation growth \n","        # and before last unit-dilated ones\n","        for i in range(n_residual_blocks):\n","          d = dilation_factors[i]\n","          model += [ResidualBlock(in_features,dilation_factor=d,r=reduction)]\n","\n","        # Upsampling\n","        out_features = in_features//2\n","        for _ in range(2):\n","            model += [  nn.utils.spectral_norm(nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1)),\n","                        nn.InstanceNorm2d(out_features),\n","                        nn.ReLU(inplace=True) ]\n","            in_features = out_features\n","            out_features = in_features//2\n","\n","        # Output layer\n","        model += [  nn.ReflectionPad2d(3),\n","                    nn.utils.spectral_norm(nn.Conv2d(64, output_nc, 7)) ]\n","                    #nn.Tanh() ]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x):\n","        return (self.model(x) + x).tanh() #(min=-1, max=1) #just learn a residual\n","\n","\n","class Generator_F2S(nn.Module):\n","    def __init__(self, input_nc, output_nc, n_residual_blocks=9,\n","                 dilation_factors=[1,1,1,2,4,8,16,1,1],\n","                 reduction=4):\n","        super(Generator_F2S, self).__init__()\n","        assert len(dilation_factors) == n_residual_blocks\n","\n","        # Initial convolution block\n","        model = [   nn.ReflectionPad2d(3),\n","                    nn.utils.spectral_norm(nn.Conv2d(input_nc+1, 64, 7)), # + mask\n","                    nn.InstanceNorm2d(64),\n","                    nn.ReLU(inplace=True) ]\n","\n","        # Downsampling\n","        in_features = 64\n","        out_features = in_features*2\n","        for _ in range(2):\n","            model += [  nn.utils.spectral_norm(nn.Conv2d(in_features, out_features, 3, stride=2, padding=1)),\n","                        nn.InstanceNorm2d(out_features),\n","                        nn.ReLU(inplace=True) ]\n","            in_features = out_features\n","            out_features = in_features*2\n","\n","        # Residual blocks\n","        for i in range(n_residual_blocks):\n","          d = dilation_factors[i]\n","          model += [ResidualBlock(in_features,dilation_factor=d,r=reduction)]\n","\n","        # Upsampling\n","        out_features = in_features//2\n","        for _ in range(2):\n","            model += [  nn.utils.spectral_norm(nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1)),\n","                        nn.InstanceNorm2d(out_features),\n","                        nn.ReLU(inplace=True) ]\n","            in_features = out_features\n","            out_features = in_features//2\n","\n","        # Output layer\n","        model += [  nn.ReflectionPad2d(3),\n","                    nn.utils.spectral_norm(nn.Conv2d(64, output_nc, 7)) ]\n","                    #nn.Tanh() ]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x, mask):\n","        return (self.model(torch.cat((x, mask), 1)) + x).tanh() #(min=-1, max=1) #just learn a residual\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, input_nc):\n","        super(Discriminator, self).__init__()\n","\n","        # A bunch of convolutions one after another\n","        \n","        model = [nn.utils.spectral_norm(nn.Conv2d(input_nc, 64, 4, stride=2, padding=1)),\n","                 nn.LeakyReLU(0.2, inplace=True) ]\n","\n","        model += [nn.utils.spectral_norm(nn.Conv2d(64, 128, 4, stride=2, padding=1)),\n","                  nn.InstanceNorm2d(128),\n","                  nn.LeakyReLU(0.2, inplace=True) ]\n","\n","        model += [nn.utils.spectral_norm(nn.Conv2d(128, 256, 4, stride=2, padding=1)),\n","                  nn.InstanceNorm2d(256),\n","                  nn.LeakyReLU(0.2, inplace=True) ]\n","\n","        model += [nn.utils.spectral_norm(nn.Conv2d(256, 512, 4, padding=1)),\n","                  nn.InstanceNorm2d(512),\n","                  nn.LeakyReLU(0.2, inplace=True) ]\n","\n","        # FCN classification layer\n","        model += [nn.utils.spectral_norm(nn.Conv2d(512, 1, 4, padding=1))]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x):\n","        x =  self.model(x)\n","        # Average pooling and flatten\n","        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1) #global avg pool"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0YJi52j7GIi1","colab_type":"text"},"source":["### Buffers"]},{"cell_type":"code","metadata":{"id":"Eek1JNenFvmu","colab_type":"code","colab":{}},"source":["class ReplayBuffer():\n","    def __init__(self, max_size=50):\n","        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n","        self.max_size = max_size\n","        self.data = []\n","\n","    def push_and_pop(self, data):\n","        to_return = []\n","        for element in data.data:\n","            element = torch.unsqueeze(element, 0)\n","            if len(self.data) < self.max_size:\n","                self.data.append(element)\n","                to_return.append(element)\n","            else:\n","                if random.uniform(0,1) > 0.5:\n","                    i = random.randint(0, self.max_size-1)\n","                    to_return.append(self.data[i].clone())\n","                    self.data[i] = element\n","                else:\n","                    to_return.append(element)\n","        return Variable(torch.cat(to_return))\n","\n","class QueueMask():\n","    def __init__(self, length):\n","        self.max_length = length\n","        self.queue = []\n","\n","    def insert(self, mask):\n","        if self.queue.__len__() >= self.max_length:\n","            self.queue.pop(0)\n","\n","        self.queue.append(mask)\n","\n","    def rand_item(self):\n","        assert self.queue.__len__() > 0, 'Error! Empty queue!'\n","        return self.queue[np.random.randint(0, self.queue.__len__())]\n","\n","    def last_item(self):\n","        assert self.queue.__len__() > 0, 'Error! Empty queue!'\n","        return self.queue[self.queue.__len__()-1]\n","        \n","\n","class ImageDatasetHDF5(Dataset):\n","    def __init__(self, path_hdf5, transforms_=None):\n","        self.transform = transforms.Compose(transforms_)\n","        self.files = h5py.File(path_hdf5, \"r\")\n","        self.domain_A = 'domain_A'\n","        self.domain_B = 'domain_B'\n","\n","        self.length_A = self.files[self.domain_A].shape[0]\n","        self.length_B = self.files[self.domain_B].shape[0]\n","\n","    @timer\n","    def __getitem__(self, index):\n","        item_A = self.transform(self.files[self.domain_A][index % self.length_A])\n","        item_B = self.transform(self.files[self.domain_B][random.randint(0, self.length_B - 1)])\n","        return {'A': item_A, 'B': item_B}\n","\n","    def __len__(self):\n","        return max(self.length_A, self.length_B)\n","\n","\n","class ImageDatasetValidation(Dataset):\n","    def __init__(self, root, paired=False, transforms_=None, mode='val'):\n","        self.transform = transforms.Compose(transforms_)\n","        self.paired = paired\n","        self.files_A = sorted(glob.glob(os.path.join(root, f'{mode}/{mode}_A', '*.png')))\n","        self.files_B = sorted(glob.glob(os.path.join(root, f'{mode}/{mode}_C', '*.png')))\n","\n","    def __getitem__(self, index):\n","        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n","        if self.paired:\n","          item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\n","          return {'A': item_A, 'B': item_B}  \n","        item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]))\n","        return {'A': item_A, 'B': item_B}\n","\n","    def __len__(self):\n","        return max(len(self.files_A), len(self.files_B))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ih5jjEJIGPwI","colab_type":"text"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"KsAG2hLaFyt5","colab_type":"code","colab":{}},"source":["to_pil = transforms.ToPILImage()\n","to_gray = transforms.Grayscale(num_output_channels=1)\n","\n","\n","def mask_generator(shadow, shadow_free):\n","\tim_f = to_gray(to_pil(((shadow_free.data.squeeze(0) + 1.0) * 0.5).cpu()))\n","\tim_s = to_gray(to_pil(((shadow.data.squeeze(0) + 1.0) * 0.5).cpu()))\n","\n","\tdiff = (np.asarray(im_f, dtype='float32')- np.asarray(im_s, dtype='float32')) # difference between shadow image and shadow_free image\n","\tL = threshold_otsu(diff)\n","\tmask = torch.tensor((np.float32(diff >= L)-0.5)/0.5).unsqueeze(0).unsqueeze(0).cuda() #-1.0:non-shadow, 1.0:shadow\n","\tmask.requires_grad = False\n","\treturn mask\n","\n","\n","\n","def tensor2image(tensor):\n","    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n","    if image.shape[0] == 1:\n","        image = np.tile(image, (3,1,1))\n","    return image.astype(np.uint8)\n","\n","\n","class LambdaLR():\n","    def __init__(self, n_epochs, offset, decay_start_epoch):\n","        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n","        self.n_epochs = n_epochs\n","        self.offset = offset\n","        self.decay_start_epoch = decay_start_epoch\n","\n","    def step(self, epoch):\n","        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n","\n","def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm2d') != -1:\n","        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        torch.nn.init.constant_(m.bias.data, 0.0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NRZ9EoJlwsnM","colab_type":"text"},"source":["### Evaluators"]},{"cell_type":"code","metadata":{"id":"TkuvuH0W4x7O","colab_type":"code","colab":{}},"source":["def read_paths(path):\n","  with open(path, 'rb') as f:\n","    paths = pickle.load(f)\n","  return paths\n","\n","def mkdir(path):\n","  try:\n","    os.mkdir(path)\n","  except FileExistsError as e:\n","    pass\n","\n","def save_test(A_path, B_path, save_path):\n","  start_time = time.time()\n","  A_paths = read_paths(A_path)\n","  B_paths = read_paths(B_path)\n","  \n","  assert len(A_paths) == len(B_paths)\n","  # read and preprocess the test images\n","  os.makedirs(save_path, exist_ok=True)\n","\n","  mkdir(os.path.join(save_path, 'A_B'))\n","  mkdir(os.path.join(save_path, 'B_A'))\n","\n","  mkdir(os.path.join(save_path, 'masks'))\n","\n","  # load the model\n","  netG_A2B = Generator_S2F(input_nc, output_nc).to(device)\n","  netG_B2A = Generator_F2S(input_nc, output_nc).to(device)\n","\n","\n","  # load latest checkpoint\n","  netG_A2B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_A2B.pth')))\n","  netG_B2A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_B2A.pth')))\n","\n","  # turn the validation mode\n","  netG_A2B.eval()\n","  netG_B2A.eval()\n","\n","  # input tensors\n","  Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n","  input_A = Tensor(batch_size, input_nc, image_size, image_size, 3)\n","  input_B = Tensor(batch_size, output_nc, image_size, image_size, 3)\n","\n","  # input transformations\n","  img_transforms = transforms.Compose([\n","                                       transforms.Resize((image_size, image_size), interpolation=Image.BICUBIC),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((.5,.5,.5),(.5,.5,.5))\n","  ])\n","  to_pil = transforms.ToPILImage()\n","\n","  image_queue = QueueMask(length=mask_queue_size)\n","  for i,(path_A, path_B) in enumerate(zip(A_paths, B_paths)):\n","    image_A = Image.open(path_A).convert(\"RGB\")\n","    image_B = Image.open(path_A).convert(\"RGB\")\n","\n","    im_A = (img_transforms(image_A).unsqueeze(0)).to(device)\n","    im_B = (img_transforms(image_B).unsqueeze(0)).to(device)\n","\n","  \n","\n","    # generate A -> B\n","    A_B = netG_A2B(im_A)\n","    w,h = image_A.size\n","\n","    current_mask = mask_generator(A_B, im_A)\n","    image_queue.insert(current_mask)\n","    A_B = .5 * (A_B + 1)\n","    A_B = np.array((to_pil(A_B.data.squeeze(0).cpu())))\n","    Image.fromarray(A_B).save(os.path.join(save_path, 'A_B', 'A_B_{}.jpg'.format(i)))\n","\n","    # generate B -> A\n","    mask = image_queue.rand_item()\n","    B_A = netG_B2A(im_B, mask)\n","    w,h = image_B.size\n","\n","    B_A = .5 * (B_A + 1)\n","    B_A = np.array((to_pil(B_A.data.squeeze(0).cpu())))\n","    Image.fromarray(B_A).save(os.path.join(save_path, 'B_A', 'B_A_{}.jpg'.format(i)))\n","\n","    mask_cpu = np.array((to_pil(.5 * (current_mask.data + 1).squeeze(0).cpu())))\n","    Image.fromarray(mask_cpu).save(os.path.join(save_path, 'masks', 'mask_{}.jpg'.format(i)))\n","\n","  print(\"---- Inference finished. Time : {} ----\".format(time.time() - start_time).upper())\n","  return image_queue\n","\n","\n","def save_images(image_paths, save_path, domain):\n","  try:\n","    os.mkdir(save_path)\n","  except:\n","    pass\n","\n","  for i in range(len(image_paths)):\n","    img = plt.imread(image_paths[i])\n","    plt.imsave(os.path.join(save_path,'{}_{}.jpg'.format(domain, i)), img)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7c7noBkq0TmC","colab_type":"code","colab":{}},"source":["from skimage import color, io\n","def evaluate(image_true, image_pred):\n","    image_true = convert_image_array(image_true)\n","    image_pred = convert_image_array(image_pred)\n","\n","    image_true = color.rgb2lab(image_true)\n","    image_pred = color.rgb2lab(image_pred)\n","\n","    rmse = np.sqrt(np.square(image_true - image_pred))\n","    return np.mean(rmse)\n","\n","\n","def convert_image_array(image):\n","  image = 127.5 * (image.squeeze(0) + 1)\n","  image = image.permute(1,2,0)\n","  \n","  return image.data.cpu().numpy().astype(np.uint8)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hXJjtqf5IL_o","colab_type":"text"},"source":["### Train"]},{"cell_type":"code","metadata":{"id":"sR8ZGJ5Z5_PK","colab_type":"code","colab":{}},"source":["# _ = [os.remove(os.path.join(summary_dir, path)) for path in os.listdir(summary_dir)]\n","# _ = [os.remove(os.path.join(images_dir, path)) for path in os.listdir(images_dir)]\n","# _ = [os.remove(os.path.join(checkpoint_dir, path)) for path in os.listdir(checkpoint_dir)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOpXykMJIK_a","colab_type":"code","colab":{}},"source":["checkpoint_dir = 'mask_shadow_gan/output/checkpoints/checkpoints_dilated_v0.0.1/1/'\n","images_dir = 'mask_shadow_gan/output/images/images_dilated_v0.0.1/1/'\n","summary_dir = 'mask_shadow_gan/output/summary/summary_dilated_v0.0.1/1/'\n","\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","os.makedirs(images_dir, exist_ok=True)\n","os.makedirs(summary_dir, exist_ok=True)\n","\n","root_dir = 'data/ISTD_Dataset/'\n","hdf5_file = 'data/ISTD_Dataset/hdf5_dataset/data_istd.h5'\n","\n","# validation pathes\n","A_dir_inf = 'mask_shadow_gan/output/results/test_set_meta/test_paths/ISTD/shadow_path.pickle'\n","B_dir_inf = 'mask_shadow_gan/output/results/test_set_meta/test_paths/ISTD/free_path.pickle'\n","results_dir = 'mask_shadow_gan/output/results/dilated_v.0.0.1/1'\n","\n","\n","\n","load_model = True\n","batch_size=1\n","image_size=256\n","ngf=64\n","ndf=64\n","\n","lambda1=10\n","lambda2=10\n","identity_lambda = 0.5\n","learning_rate=2e-4\n","lr_D = 4e-4  # TTUR\n","lr_G = 1e-4  # TTUR\n","\n","beta1=.5\n","mask_queue_size=50\n","slope=0.2\n","stddev=0.02\n","\n","input_nc=3\n","output_nc=3\n","\n","n_res_blocks=9\n","dilation_A2B = [1,1,1,1,1,2,2,4,8]\n","dilation_B2A = [1,1,1,1,1,2,2,4,8]\n","\n","REAL_LABEL=0.9  # label smoothing\n","reduction_factor=4\n","\n","device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","n_epochs=200\n","decay_epoch=100\n","epoch=0\n","img_snapshot=500\n","model_snapshot=5\n","log_snapshot=10\n","val_snapshot=100\n","\n","coef_identity = 5\n","coef_cycle = 10\n","coef_adv = 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nsP_efe1yU6u","colab_type":"code","colab":{}},"source":["class MaskShadowGAN(object):\n","  def __init__(self):\n","    pass\n","\n","  def build(self):\n","    ###### Definition of variables ######\n","    # Networks\n","    print(f\"------------------- Definition of variables -------------------\")\n","    \n","    self.netG_A2B = Generator_S2F(input_nc, output_nc, \n","                                  n_residual_blocks=n_res_blocks,\n","                                  dilation_factors=dilation_A2B,\n","                                  reduction=reduction_factor)  # shadow to shadow_free\n","    self.netG_B2A = Generator_F2S(output_nc, input_nc,\n","                                  n_residual_blocks=n_res_blocks,\n","                                  dilation_factors=dilation_B2A,\n","                                  reduction=reduction_factor)  # shadow_free to shadow\n","    self.netD_A = Discriminator(input_nc)\n","    self.netD_B = Discriminator(output_nc)\n","\n","\n","    self.netG_A2B.cuda()\n","    self.netG_B2A.cuda()\n","    self.netD_A.cuda()\n","    self.netD_B.cuda()\n","\n","    self.netG_A2B.apply(weights_init_normal)\n","    self.netG_B2A.apply(weights_init_normal)\n","    self.netD_A.apply(weights_init_normal)\n","    self.netD_B.apply(weights_init_normal)\n","\n","    # Lossess\n","    self.criterion_GAN = torch.nn.MSELoss()  # lsgan\n","    # criterion_GAN = torch.nn.BCEWithLogitsLoss() #vanilla\n","    self.criterion_cycle = torch.nn.L1Loss()\n","    self.criterion_identity = torch.nn.L1Loss()\n","\n","    # Optimizers & LR schedulers\n","    self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A2B.parameters(), self.netG_B2A.parameters()),\n","                    lr=lr_G, betas=(0.5, 0.999))\n","    self.optimizer_D_A = torch.optim.Adam(self.netD_A.parameters(), lr=lr_D, betas=(0.5, 0.999))\n","    self.optimizer_D_B = torch.optim.Adam(self.netD_B.parameters(), lr=lr_D, betas=(0.5, 0.999))\n","\n","    self.lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(self.optimizer_G,\n","                              lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n","    self.lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(self.optimizer_D_A,\n","                              lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n","    self.lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(self.optimizer_D_B,\n","                              lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n","    \n","    self.Tensor = torch.cuda.FloatTensor\n","    self.input_A = self.Tensor(batch_size, input_nc, image_size, image_size)\n","    self.input_B = self.Tensor(batch_size, output_nc, image_size, image_size)\n","    self.target_real = Variable(self.Tensor(batch_size).fill_(REAL_LABEL), requires_grad=False)\n","    self.target_fake = Variable(self.Tensor(batch_size).fill_(0.0), requires_grad=False)\n","    self.mask_non_shadow = Variable(self.Tensor(batch_size, 1, image_size, image_size).fill_(-1.0), requires_grad=False) #-1.0 non-shadow\n","\n","    self.fake_A_buffer = ReplayBuffer()\n","    self.fake_B_buffer = ReplayBuffer()\n","\n","    # Dataset loader\n","    self.transforms_ = [\n","            # transforms.ToPILImage(),\n","            transforms.Resize(int(image_size * 1.12), Image.BICUBIC),\n","            transforms.RandomCrop(image_size),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n","\n","    transforms_test = [\n","      transforms.Resize((image_size, image_size), interpolation=Image.BICUBIC),\n","      transforms.ToTensor(),\n","      transforms.Normalize((.5,.5,.5),(.5,.5,.5))\n","    ]\n","\n","    # self.dataloader = DataLoader(ImageDatasetHDF5(hdf5_file, transforms_=self.transforms_),\n","    #                                           batch_size=batch_size, shuffle=True, num_workers=1)\n","    \n","    self.dataloader_train = DataLoader(ImageDatasetValidation(root_dir, paired=False, \n","                                                              transforms_=self.transforms_, \n","                                                              mode='train'), \n","                                    batch_size=1, shuffle=False, num_workers=os.cpu_count())\n","    self.dataloader_val = DataLoader(ImageDatasetValidation(root_dir, paired=True, \n","                                                            transforms_=transforms_test, \n","                                                            mode='val'), \n","                                    batch_size=1, shuffle=False, num_workers=os.cpu_count())\n","    \n","\n","    \"\"\"Summary writing to tensorboard\"\"\"\n","    self.writer = SummaryWriter(log_dir=summary_dir)\n","    return self\n","    \n","\n","  def train(self):\n","    step = 0\n","    epoch = 0\n","    if load_model:\n","      print(\"Resume training\")\n","      epoch, step = self.load_model()\n","      # epoch+=1\n","\n","    to_pil = transforms.ToPILImage()\n","    mask_queue =  QueueMask(self.dataloader_train.__len__()/4)\n","\n","    ###### Training ######\n","    print(f\"------------------- Start Training -------------------\")\n","    epoch_cp = epoch\n","    try:\n","      for ep in tqdm_notebook(range(epoch, n_epochs), total=n_epochs-epoch):\n","        for i, batch in enumerate(self.dataloader_train):\n","          # Set model input\n","          # batch = _batch['result']\n","          # time_batch = _batch['time']\n","          real_A = Variable(self.input_A.copy_(batch['A']))\n","          real_B = Variable(self.input_B.copy_(batch['B']))\n","\n","          ###### Generators A2B and B2A ######\n","          start_time = time.time()\n","          self.optimizer_G.zero_grad()\n","\n","          # Identity loss\n","          # G_A2B(B) should equal B if real B is fed\n","          same_B = self.netG_A2B(real_B)\n","          loss_identity_B = self.criterion_identity(same_B, real_B)  # ||Gb(b)-b||1\n","          # G_B2A(A) should equal A if real A is fed, so the mask should be all zeros\n","          same_A = self.netG_B2A(real_A, self.mask_non_shadow)\n","          loss_identity_A = self.criterion_identity(same_A, real_A)  # ||Ga(a)-a||1\n","\n","          # GAN loss\n","          fake_B = self.netG_A2B(real_A)\n","          pred_fake = self.netD_B(fake_B)\n","          loss_GAN_A2B = self.criterion_GAN(pred_fake, self.target_real)  # log(Db(Gb(a)))\n","\n","          mask_queue.insert(mask_generator(real_A, fake_B))\n","\n","          fake_A = self.netG_B2A(real_B, mask_queue.rand_item())\n","          pred_fake = self.netD_A(fake_A)\n","          loss_GAN_B2A = self.criterion_GAN(pred_fake, self.target_real)  # log(Da(Ga(b)))\n","\n","          # Cycle loss\n","          recovered_A = self.netG_B2A(fake_B, mask_queue.last_item()) # real shadow, false shadow free\n","          loss_cycle_ABA = self.criterion_cycle(recovered_A, real_A) * 10.0  # ||Ga(Gb(a))-a||1\n","\n","          recovered_B = self.netG_A2B(fake_A)\n","          loss_cycle_BAB = self.criterion_cycle(recovered_B, real_B) * 10.0  # ||Gb(Ga(b))-b||1\n","\n","          # Total loss\n","          loss_G = coef_identity * (loss_identity_A + loss_identity_B) + \\\n","            coef_adv * (loss_GAN_A2B + loss_GAN_B2A) + coef_cycle * (loss_cycle_ABA + loss_cycle_BAB)\n","\n","          time_G_forward = time.time() - start_time\n","\n","          start_time = time.time()\n","          loss_G.backward()\n","          self.optimizer_G.step()\n","          time_G_backward = time.time() - start_time\n","\n","          ###################################\n","\n","          ###### Discriminator A ######\n","          start_time = time.time()\n","          self.optimizer_D_A.zero_grad()\n","\n","          # Real loss\n","          pred_real = self.netD_A(real_A)\n","          loss_D_real = self.criterion_GAN(pred_real, self.target_real)  # log(Da(a))\n","\n","          # Fake loss\n","          fake_A = self.fake_A_buffer.push_and_pop(fake_A)\n","          pred_fake = self.netD_A(fake_A.detach())\n","          loss_D_fake = self.criterion_GAN(pred_fake, self.target_fake)  # log(1-Da(G(b)))\n","\n","          # Total loss\n","          loss_D_A = (loss_D_real + loss_D_fake) * 0.5 * coef_adv\n","          time_DA_forward = time.time() - start_time\n","          \n","          start_time = time.time()\n","          loss_D_A.backward()\n","\n","          self.optimizer_D_A.step()\n","          time_DA_backward = time.time() - start_time\n","\n","          ###################################\n","\n","          ###### Discriminator B ######\n","          start_time = time.time()\n","          self.optimizer_D_B.zero_grad()\n","\n","          # Real loss\n","          pred_real = self.netD_B(real_B)\n","          loss_D_real = self.criterion_GAN(pred_real, self.target_real)  # log(Db(b))\n","\n","          # Fake loss\n","          fake_B = self.fake_B_buffer.push_and_pop(fake_B)\n","          pred_fake = self.netD_B(fake_B.detach())\n","          loss_D_fake = self.criterion_GAN(pred_fake, self.target_fake)  # log(1-Db(G(a)))\n","\n","          # Total loss\n","          loss_D_B = (loss_D_real + loss_D_fake) * 0.5 * coef_adv\n","          time_DB_forward = time.time() - start_time\n","\n","          start_time = time.time()\n","\n","          loss_D_B.backward()\n","          self.optimizer_D_B.step()\n","\n","          time_DB_backward = time.time() - start_time\n","          ###################################\n","\n","          step += 1\n","          if step % img_snapshot == 0:\n","            img_fake_A = 0.5 * (fake_A.detach().data + 1.0)\n","            img_fake_A = (to_pil(img_fake_A.data.squeeze(0).cpu()))\n","            img_fake_A.save(os.path.join(images_dir, f\"fake_A_{step}.png\"))\n","\n","            img_fake_B = 0.5 * (fake_B.detach().data + 1.0)\n","            img_fake_B = (to_pil(img_fake_B.data.squeeze(0).cpu()))\n","            img_fake_B.save(os.path.join(images_dir, f\"fake_B_{step}.png\"))\n","\n","          # logging\n","          if step % log_snapshot == 0:\n","            self.writer.add_scalar('G/GAN_A2B', loss_GAN_A2B, global_step=step)\n","            self.writer.add_scalar('G/GAN_B2A', loss_GAN_B2A, global_step=step)\n","            self.writer.add_scalar('G/cycle_ABA', loss_cycle_ABA, global_step=step)\n","            self.writer.add_scalar('G/cycle_BAB', loss_cycle_BAB, global_step=step)\n","            self.writer.add_scalar('G/idt_A', loss_identity_A, global_step=step)\n","            self.writer.add_scalar('G/idt_B', loss_identity_B, global_step=step)\n","\n","            self.writer.add_scalar('D/D_A', loss_D_A, global_step=step)\n","            self.writer.add_scalar('D/D_B', loss_D_B, global_step=step)\n","\n","            # time tracking\n","            # self.writer.add_scalar('T/batch', time_batch, global_step=step)\n","            # self.writer.add_scalar('T/G_forward', time_G_forward, global_step=step)\n","            # self.writer.add_scalar('T/G_backward', time_G_backward, global_step=step)\n","\n","            # self.writer.add_scalar('T/D_A_forward', time_DA_forward, global_step=step)\n","            # self.writer.add_scalar('T/D_A_backward', time_DA_backward, global_step=step)\n","\n","            # self.writer.add_scalar('T/D_B_forward', time_DB_forward, global_step=step)\n","            # self.writer.add_scalar('T/D_B_backward', time_DB_backward, global_step=step)\n","\n","          # validation\n","          if step % val_snapshot == 0:\n","            val_input_A = self.Tensor(1, 3, image_size, image_size)\n","            val_input_B = self.Tensor(1, 3, image_size, image_size)\n","            self.netG_A2B.eval()\n","            scores = []\n","            for batch_val in self.dataloader_val:\n","              real_A = Variable(val_input_A.copy_(batch_val['A']))\n","              real_B = Variable(val_input_B.copy_(batch_val['B']))\n","\n","              pred_B = self.netG_A2B(real_A)\n","              score = evaluate(real_B, pred_B)\n","              scores.append(score)\n","            self.writer.add_scalar('Score/val_rmse', np.mean(scores), global_step=step)\n","            self.netG_A2B.train()\n","\n","\n","\n","        # Update learning rates\n","        self.lr_scheduler_G.step()\n","        self.lr_scheduler_D_A.step()\n","        self.lr_scheduler_D_B.step()\n","\n","\n","        # Save models checkpoints\n","        if ep % model_snapshot == 0:\n","          print(f\"Save model -- epoch: {ep}, step: {step}\")\n","          self.save_model(ep, step)\n","\n","          print('Run validation...')\n","          save_test(A_dir_inf, B_dir_inf, os.path.join(results_dir, f'msg_{ep}'))\n","\n","        epoch_cp = ep\n","\n","\n","    except Exception as e:\n","      raise e\n","    finally:\n","      print(f\"Save model -- epoch: {epoch_cp}, step: {step}\")\n","      self.save_model(epoch_cp, step)\n","\n","  def _get_param_by_name(self, model, param_name):\n","    params = [x[1] for x in model.named_parameters() if param_name in x[0]]\n","    return {i:val for (i,val) in enumerate(params)}\n","\n","  def save_model(self, epoch_num, step):\n","    np.savetxt(os.path.join(checkpoint_dir, 'epoch_num.txt'), [epoch_num])\n","    np.savetxt(os.path.join(checkpoint_dir, 'step.txt'), [step])\n","\n","    torch.save(self.netG_A2B.state_dict(), os.path.join(checkpoint_dir, 'netG_A2B.pth'))\n","    torch.save(self.netG_B2A.state_dict(), os.path.join(checkpoint_dir, 'netG_B2A.pth'))\n","    torch.save(self.netD_A.state_dict(), os.path.join(checkpoint_dir, 'netD_A.pth'))\n","    torch.save(self.netD_B.state_dict(), os.path.join(checkpoint_dir, 'netD_B.pth'))\n","\n","    torch.save(self.optimizer_G.state_dict(), os.path.join(checkpoint_dir, 'optimizer_G.pth'))\n","    torch.save(self.optimizer_D_A.state_dict(), os.path.join(checkpoint_dir, 'optimizer_D_A.pth'))\n","    torch.save(self.optimizer_D_B.state_dict(), os.path.join(checkpoint_dir, 'optimizer_D_B.pth'))\n","\n","    torch.save(self.lr_scheduler_G.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_G.pth'))\n","    torch.save(self.lr_scheduler_D_A.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_D_A.pth'))\n","    torch.save(self.lr_scheduler_D_B.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_D_B.pth'))\n","\n","\n","  def load_model(self):\n","    epoch = int(np.loadtxt(os.path.join(checkpoint_dir, 'epoch_num.txt')))\n","    step  = int(np.loadtxt(os.path.join(checkpoint_dir, 'step.txt')))\n","    \n","    self.netG_A2B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_A2B.pth')))\n","    self.netG_B2A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_B2A.pth')))\n","    self.netD_A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netD_A.pth')))\n","    self.netD_B.load_state_dict(torch.load((os.path.join(checkpoint_dir, 'netD_B.pth'))))\n","\n","    self.optimizer_G.load_state_dict(torch.load((os.path.join(checkpoint_dir, 'optimizer_G.pth'))))\n","    self.optimizer_D_A.load_state_dict(torch.load((os.path.join(checkpoint_dir, 'optimizer_D_A.pth'))))\n","    self.optimizer_D_B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'optimizer_D_B.pth')))\n","\n","    self.lr_scheduler_G.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'lr_scheduler_G.pth')))\n","    self.lr_scheduler_D_A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'lr_scheduler_D_A.pth')))\n","    self.lr_scheduler_D_B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'lr_scheduler_D_B.pth')))\n","    print(f\"Model loaded -- {epoch}:{step}\")\n","    return epoch, step"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6OA37Kg-bSj","colab_type":"code","outputId":"56b575dc-2aed-4ea4-b49f-4c4f0082e7c8","executionInfo":{"status":"ok","timestamp":1584753367205,"user_tz":-120,"elapsed":43352,"user":{"displayName":"Владислав Андроник","photoUrl":"","userId":"15929840215236502543"}},"colab":{"base_uri":"https://localhost:8080/","height":81}},"source":["model = MaskShadowGAN().build()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["------------------- Definition of variables -------------------\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"jRM6TxxT-e9t","colab_type":"code","colab":{}},"source":["# turn on save!!!\n","model.train()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m3zO5Ja0yW54","colab_type":"code","colab":{}},"source":["\"\"\"\n","function preventFromOff(){\n","  console.log(\"Click button\");\n","  document.querySelector(\"colab-connect-button\").shadowRoot.getElementById(\"connect\").click()\n","}\n","var timeout = 8 * 60 * 60 * 1000;\n","var delay = 3 * 60 * 1000;\n","var refreshId = setInterval(preventFromOff, delay);\n","setTimeout(() => {clearInterval(refreshId); console.log(\"Stopped script\");}, timeout);\n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghBRHmI13azj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}