{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mask-shadow-v0.1.1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d4d9d62dbdf7462091157acf55ba10d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6c96ba10f6bf4706bed7accb7a5ee63b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e0fa50b42d01498c9e51a4c5614f6f45","IPY_MODEL_3d1af278db0744e7a76cad8063c670a7"]}},"6c96ba10f6bf4706bed7accb7a5ee63b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0fa50b42d01498c9e51a4c5614f6f45":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a50dcecf117d44e0825c80639933cdb2","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ceefaef75b0b48afb01a2ee9342810c8"}},"3d1af278db0744e7a76cad8063c670a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f8636826d23e45ec86bbb6d9b303623e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"  0% 0/3 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a83a9de6559c4b8baad9b1468df1b6c0"}},"a50dcecf117d44e0825c80639933cdb2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ceefaef75b0b48afb01a2ee9342810c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8636826d23e45ec86bbb6d9b303623e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a83a9de6559c4b8baad9b1468df1b6c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"E-uL7m4MOnYr","colab_type":"text"},"source":["## Version 0.1.1\n","- Architectural changes\n","  - Dilated convolutions (+)\n","  - SENet (+)\n","\n","- Stable training\n","  - Spectral normalization (+)\n","  - Label smoothing (+)\n","  - TTUR (+)"]},{"cell_type":"code","metadata":{"id":"Ff1KlQV0DqVi","colab_type":"code","outputId":"57121454-d306-4a0b-abdf-bc870c44dee5","executionInfo":{"status":"ok","timestamp":1584364650957,"user_tz":-120,"elapsed":413612,"user":{"displayName":"Владислав Андроник","photoUrl":"","userId":"15929840215236502543"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive/')\n","path_basic = 'drive/My Drive/gan_experiments'\n","os.chdir(path_basic)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O7yWhzb23gfB","colab_type":"code","outputId":"3caf7a69-1387-4a6f-d468-078f87bfbd03","executionInfo":{"status":"ok","timestamp":1584183623498,"user_tz":-120,"elapsed":14640,"user":{"displayName":"Vlad Andronik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhbMGxHkjokCi9rObSClj5lf1eT5AbYqBaXBHWUw=s64","userId":"00447066830077822735"}},"colab":{"base_uri":"https://localhost:8080/","height":279}},"source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(f\"GPU name: {gpu.name}\")\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=b37b26575b7f87f8c6c60c1e72ff3a76958a39997fe2fb9abe351038238508ae\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","GPU name: Tesla P100-PCIE-16GB\n","Gen RAM Free: 12.8 GB  | Proc size: 157.9 MB\n","GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T8D1inaltHf_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYfHqjw2EO6Z","colab_type":"code","colab":{}},"source":["import torch\n","from torch.nn import init\n","from torch import nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader,Dataset\n","from torch.autograd import Variable\n","from torch.utils.tensorboard import SummaryWriter \n","\n","from skimage.filters import threshold_otsu\n","import cv2\n","from PIL import Image\n","import functools\n","import itertools\n","import numpy as np\n","import random\n","\n","import os\n","import sys\n","import glob\n","from tqdm import tqdm_notebook\n","import re\n","\n","import matplotlib.pyplot as plt\n","import pickle\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9eU38c1glQDp","colab_type":"text"},"source":["### Additional modules implementation"]},{"cell_type":"markdown","metadata":{"id":"CJ55xE2slUcK","colab_type":"text"},"source":["#### Dilated convolutions"]},{"cell_type":"code","metadata":{"id":"nXvdpUrTXYer","colab_type":"code","colab":{}},"source":["# test block(not used further)\n","class DilatedBlock(nn.Module):\n","  def __init__(self, dilations):\n","    super(DilatedBlock ,self).__init__()\n","    self.dilations = dilations\n","    k=3\n","    for d in dilations:\n","      p = int(((k - 1) * (d - 1) + k - 1) / 2)\n","      setattr(self, f\"conv_{d}\", nn.Conv2d(3,3,3,dilation=d,padding=p))\n","\n","  def forward(self, x):\n","    print(f\"Input shape: {x.shape}\")\n","    h = self.conv_1(x)\n","\n","    for d in self.dilations:\n","      x = getattr(self, f\"conv_{d}\")(x)\n","      print(f\"Dilation-{d} shape: {x.shape}\")\n","    return h"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_SHjh7dtY0Cu","colab_type":"code","outputId":"a8486fa9-ba70-4a88-be83-cd53ba289cdd","executionInfo":{"status":"ok","timestamp":1584364707358,"user_tz":-120,"elapsed":29427,"user":{"displayName":"Владислав Андроник","photoUrl":"","userId":"15929840215236502543"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["inp = torch.rand(1,3,64,64,)\n","dilations = [1,1,2,4,8,16,64,1]\n","model = DilatedBlock(dilations)\n","_ = model(inp)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Input shape: torch.Size([1, 3, 64, 64])\n","Dilation-1 shape: torch.Size([1, 3, 64, 64])\n","Dilation-1 shape: torch.Size([1, 3, 64, 64])\n","Dilation-2 shape: torch.Size([1, 3, 64, 64])\n","Dilation-4 shape: torch.Size([1, 3, 64, 64])\n","Dilation-8 shape: torch.Size([1, 3, 64, 64])\n","Dilation-16 shape: torch.Size([1, 3, 64, 64])\n","Dilation-64 shape: torch.Size([1, 3, 64, 64])\n","Dilation-1 shape: torch.Size([1, 3, 64, 64])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xwKQOK20lahk","colab_type":"code","colab":{}},"source":["class SENet(nn.Module):\n","  def __init__(self, input_nc, r=16):\n","    super(SENet, self).__init__()\n","    self.input_nc = input_nc\n","    self.fc1 = nn.utils.spectral_norm(nn.Linear(input_nc, int(input_nc / r)))\n","    self.relu = nn.ReLU()\n","    self.fc2 = nn.utils.spectral_norm(nn.Linear(int(input_nc / r), input_nc))\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, x):\n","    input_dim = x.shape[2]\n","    gap = F.avg_pool2d(x, input_dim)\n","    gap = gap.view(gap.shape[0], -1)\n","\n","    h = self.fc1(gap)\n","    h = self.relu(h)\n","    h = self.fc2(h)\n","    attn = self.sigmoid(h)\n","\n","    output = x * attn.unsqueeze(2).unsqueeze(3)\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WR9tCyT11OoA","colab":{}},"source":["in_data = torch.rand(1,32,32,32)\n","model = SENet(32)\n","out = model(in_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tbal9TpD3K2i","colab_type":"code","colab":{}},"source":["# timer utils\n","import time\n","import functools\n","def timer(f):\n","  @functools.wraps(f)\n","  def wrapper(*args, **kwargs):\n","    start_time = time.time()\n","    r = f(*args, **kwargs)\n","    duration = time.time() - start_time\n","    result = {\n","        'result':r,\n","        'time':duration\n","    }\n","    return result\n","  return wrapper"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"llViHAJ2EPEn","colab_type":"text"},"source":["### Blocks"]},{"cell_type":"code","metadata":{"id":"hM7rtwdjEPAO","colab_type":"code","colab":{}},"source":["class ResidualBlock(nn.Module):\n","    \"\"\"\n","      SEDResidualBlock\n","      Parameters:\n","        dilation_factor -- dilated convolution hyperparam\n","        r -- reduction factor for SE bottleneck\n","    \"\"\"\n","    def __init__(self, in_features, dilation_factor, r=4):\n","        super(ResidualBlock, self).__init__()\n","        k = 3\n","        d = dilation_factor\n","        pad = int(((k - 1) * (d - 1) + k - 1) / 2)\n","\n","        conv_block = [  nn.ReflectionPad2d(pad),\n","                        nn.utils.spectral_norm(nn.Conv2d(in_features, in_features, 3, dilation=d)),\n","                        nn.InstanceNorm2d(in_features),\n","                        nn.ReLU(inplace=True),\n","                      \n","                        nn.ReflectionPad2d(pad),\n","                        nn.utils.spectral_norm(nn.Conv2d(in_features, in_features, 3, dilation=d)),\n","                        nn.InstanceNorm2d(in_features),\n","                        SENet(in_features, r=r)\n","                      ]\n","\n","        self.conv_block = nn.Sequential(*conv_block)\n","\n","    def forward(self, x):\n","        return x + self.conv_block(x)\n","\n","\n","class Generator_S2F(nn.Module):\n","    def __init__(self, input_nc, output_nc, n_residual_blocks=9,\n","                 dilation_factors=[1,1,2,4,8,16,2,1,1],\n","                 reduction=4):\n","        super(Generator_S2F, self).__init__()\n","        assert len(dilation_factors) == n_residual_blocks\n","\n","        # Initial convolution block\n","        model = [   nn.ReflectionPad2d(3),\n","                    nn.utils.spectral_norm(nn.Conv2d(input_nc, 64, 7)),\n","                    nn.InstanceNorm2d(64),\n","                    nn.ReLU(inplace=True) ]\n","\n","        # Downsampling\n","        in_features = 64\n","        out_features = in_features*2\n","        for _ in range(2):\n","            model += [  nn.utils.spectral_norm(nn.Conv2d(in_features, out_features, 3, stride=2, padding=1)),\n","                        nn.InstanceNorm2d(out_features),\n","                        nn.ReLU(inplace=True) ]\n","            in_features = out_features\n","            out_features = in_features*2\n","\n","        # Residual blocks\n","        for i in range(n_residual_blocks):\n","          d = dilation_factors[i]\n","          model += [ResidualBlock(in_features,dilation_factor=d,r=reduction)]\n","\n","        # Upsampling\n","        out_features = in_features//2\n","        for _ in range(2):\n","            model += [  nn.utils.spectral_norm(nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1)),\n","                        nn.InstanceNorm2d(out_features),\n","                        nn.ReLU(inplace=True) ]\n","            in_features = out_features\n","            out_features = in_features//2\n","\n","        # Output layer\n","        model += [  nn.ReflectionPad2d(3),\n","                    nn.utils.spectral_norm(nn.Conv2d(64, output_nc, 7)) ]\n","                    #nn.Tanh() ]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x):\n","        return (self.model(x) + x).tanh() #(min=-1, max=1) #just learn a residual\n","\n","\n","class Generator_F2S(nn.Module):\n","    def __init__(self, input_nc, output_nc, n_residual_blocks=9,\n","                 dilation_factors=[1,1,2,4,8,16,2,1,1],\n","                 reduction=4):\n","        super(Generator_F2S, self).__init__()\n","        assert len(dilation_factors) == n_residual_blocks\n","\n","        # Initial convolution block\n","        model = [   nn.ReflectionPad2d(3),\n","                    nn.utils.spectral_norm(nn.Conv2d(input_nc+1, 64, 7)), # + mask\n","                    nn.InstanceNorm2d(64),\n","                    nn.ReLU(inplace=True) ]\n","\n","        # Downsampling\n","        in_features = 64\n","        out_features = in_features*2\n","        for _ in range(2):\n","            model += [  nn.utils.spectral_norm(nn.Conv2d(in_features, out_features, 3, stride=2, padding=1)),\n","                        nn.InstanceNorm2d(out_features),\n","                        nn.ReLU(inplace=True) ]\n","            in_features = out_features\n","            out_features = in_features*2\n","\n","        # Residual blocks\n","        for i in range(n_residual_blocks):\n","          d = dilation_factors[i]\n","          model += [ResidualBlock(in_features, dilation_factor=d, r=reduction)]\n","\n","        # Upsampling\n","        out_features = in_features//2\n","        for _ in range(2):\n","            model += [  nn.utils.spectral_norm(nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1)),\n","                        nn.InstanceNorm2d(out_features),\n","                        nn.ReLU(inplace=True) ]\n","            in_features = out_features\n","            out_features = in_features//2\n","\n","        # Output layer\n","        model += [  nn.ReflectionPad2d(3),\n","                    nn.utils.spectral_norm(nn.Conv2d(64, output_nc, 7)) ]\n","                    #nn.Tanh() ]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x, mask):\n","        return (self.model(torch.cat((x, mask), 1)) + x).tanh() #(min=-1, max=1) #just learn a residual\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, input_nc):\n","        super(Discriminator, self).__init__()\n","\n","        # A bunch of convolutions one after another\n","        \n","        model = [nn.utils.spectral_norm(nn.Conv2d(input_nc, 64, 4, stride=2, padding=1)),\n","                 nn.LeakyReLU(0.2, inplace=True) ]\n","\n","        model += [nn.utils.spectral_norm(nn.Conv2d(64, 128, 4, stride=2, padding=1)),\n","                  nn.InstanceNorm2d(128),\n","                  nn.LeakyReLU(0.2, inplace=True) ]\n","\n","        model += [nn.utils.spectral_norm(nn.Conv2d(128, 256, 4, stride=2, padding=1)),\n","                  nn.InstanceNorm2d(256),\n","                  nn.LeakyReLU(0.2, inplace=True) ]\n","\n","        model += [nn.utils.spectral_norm(nn.Conv2d(256, 512, 4, padding=1)),\n","                  nn.InstanceNorm2d(512),\n","                  nn.LeakyReLU(0.2, inplace=True) ]\n","\n","        # FCN classification layer\n","        model += [nn.utils.spectral_norm(nn.Conv2d(512, 1, 4, padding=1))]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x):\n","        x =  self.model(x)\n","        # Average pooling and flatten\n","        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1) #global avg pool"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jA94Xhm-4iC6","colab_type":"code","colab":{}},"source":["# V0.1.0 num params\n","V010_G = 45.512\n","V010_D = 11.058\n","V010_S = 56.57"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmLiqfXt4ecT","colab_type":"code","outputId":"53fbee67-50b8-4e81-be16-2b3580672ccc","executionInfo":{"status":"ok","timestamp":1584364707434,"user_tz":-120,"elapsed":19711,"user":{"displayName":"Владислав Андроник","photoUrl":"","userId":"15929840215236502543"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["# summary of the models\n","def num_params(model):\n","  model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","  params = sum([np.prod(p.size()) for p in model_parameters])\n","  return params\n","\n","dL = Discriminator(3)\n","g = Generator_S2F(3,3, reduction=4)\n","\n","V011_D = round(num_params(dL) * 2 / 1e6, 3) * 2\n","V011_G = round(num_params(g) * 2 / 1e6, 3) * 2\n","V011_S = round(V011_D + V011_G, 3)\n","\n","print('---- Summary models ----')\n","print(\"Number of parameters (in millions):\")\n","print(\"{:10}{:10}{:20}\".format(\"D\", 'G', \"Overall\"))\n","print(\"{:10}{:10}{:20}\".format(str(V011_D), str(V011_G), str(V011_S)))\n","\n","print(f\"GAIN PARAMS: {round((V011_S / V010_S - 1) * 100, 3)}%\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["---- Summary models ----\n","Number of parameters (in millions):\n","D         G         Overall             \n","11.058    46.704    57.762              \n","GAIN PARAMS: 2.107%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0YJi52j7GIi1","colab_type":"text"},"source":["### Buffers"]},{"cell_type":"code","metadata":{"id":"Eek1JNenFvmu","colab_type":"code","colab":{}},"source":["class ReplayBuffer():\n","    def __init__(self, max_size=50):\n","        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n","        self.max_size = max_size\n","        self.data = []\n","\n","    def push_and_pop(self, data):\n","        to_return = []\n","        for element in data.data:\n","            element = torch.unsqueeze(element, 0)\n","            if len(self.data) < self.max_size:\n","                self.data.append(element)\n","                to_return.append(element)\n","            else:\n","                if random.uniform(0,1) > 0.5:\n","                    i = random.randint(0, self.max_size-1)\n","                    to_return.append(self.data[i].clone())\n","                    self.data[i] = element\n","                else:\n","                    to_return.append(element)\n","        return Variable(torch.cat(to_return))\n","\n","# class ImageDataset(Dataset):\n","#     def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n","#         self.transform = transforms.Compose(transforms_)\n","#         self.unaligned = unaligned\n","\n","#         self.files_A = sorted(glob.glob(os.path.join(root, 'shadow_train') + '/*.*'))\n","#         self.files_B = sorted(glob.glob(os.path.join(root, 'shadow_free') + '/*.*'))\n","\n","#     def __getitem__(self, index):\n","#         item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n","\n","#         if self.unaligned:\n","#             item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]))\n","#         else:\n","#             item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\n","\n","#         return {'A': item_A, 'B': item_B}\n","\n","#     def __len__(self):\n","#         return max(len(self.files_A), len(self.files_B))\n","\n","\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, root, transforms_=None, mode='train'):\n","        self.transform = transforms.Compose(transforms_)\n","        self.files_A = sorted(glob.glob(os.path.join(root, '%s/train_A' % mode) + '/*.*'))\n","        self.files_B = sorted(glob.glob(os.path.join(root, '%s/train_C' % mode) + '/*.*'))\n","\n","    @timer\n","    def __getitem__(self, index):\n","        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n","        item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]))\n","        return {'A': item_A, 'B': item_B}\n","\n","    def __len__(self):\n","        return max(len(self.files_A), len(self.files_B))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ih5jjEJIGPwI","colab_type":"text"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"KsAG2hLaFyt5","colab_type":"code","colab":{}},"source":["to_pil = transforms.ToPILImage()\n","to_gray = transforms.Grayscale(num_output_channels=1)\n","\n","class QueueMask():\n","    def __init__(self, length):\n","        self.max_length = length\n","        self.queue = []\n","\n","    def insert(self, mask):\n","        if self.queue.__len__() >= self.max_length:\n","            self.queue.pop(0)\n","\n","        self.queue.append(mask)\n","\n","    def rand_item(self):\n","        assert self.queue.__len__() > 0, 'Error! Empty queue!'\n","        return self.queue[np.random.randint(0, self.queue.__len__())]\n","\n","    def last_item(self):\n","        assert self.queue.__len__() > 0, 'Error! Empty queue!'\n","        return self.queue[self.queue.__len__()-1]\n","\n","\n","def mask_generator(shadow, shadow_free):\n","\tim_f = to_gray(to_pil(((shadow_free.data.squeeze(0) + 1.0) * 0.5).cpu()))\n","\tim_s = to_gray(to_pil(((shadow.data.squeeze(0) + 1.0) * 0.5).cpu()))\n","\n","\tdiff = (np.asarray(im_f, dtype='float32')- np.asarray(im_s, dtype='float32')) # difference between shadow image and shadow_free image\n","\tL = threshold_otsu(diff)\n","\tmask = torch.tensor((np.float32(diff >= L)-0.5)/0.5).unsqueeze(0).unsqueeze(0).cuda() #-1.0:non-shadow, 1.0:shadow\n","\tmask.requires_grad = False\n","\treturn mask\n","\n","\n","\n","def tensor2image(tensor):\n","    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n","    if image.shape[0] == 1:\n","        image = np.tile(image, (3,1,1))\n","    return image.astype(np.uint8)\n","\n","\n","class LambdaLR():\n","    def __init__(self, n_epochs, offset, decay_start_epoch):\n","        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n","        self.n_epochs = n_epochs\n","        self.offset = offset\n","        self.decay_start_epoch = decay_start_epoch\n","\n","    def step(self, epoch):\n","        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n","\n","def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm2d') != -1:\n","        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        torch.nn.init.constant_(m.bias.data, 0.0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TkuvuH0W4x7O","colab_type":"code","colab":{}},"source":["def read_paths(path):\n","  with open(path, 'rb') as f:\n","    paths = pickle.load(f)\n","  return paths\n","\n","def mkdir(path):\n","  try:\n","    os.mkdir(path)\n","  except FileExistsError as e:\n","    pass\n","\n","def save_test(A_path, B_path, save_path):\n","  start_time = time.time()\n","  A_paths = read_paths(A_path)\n","  B_paths = read_paths(B_path)\n","  \n","  assert len(A_paths) == len(B_paths)\n","  # read and preprocess the test images\n","  os.makedirs(save_path, exist_ok=True)\n","\n","  mkdir(os.path.join(save_path, 'A_B'))\n","  mkdir(os.path.join(save_path, 'B_A'))\n","\n","  mkdir(os.path.join(save_path, 'masks'))\n","\n","  # load the model\n","  netG_A2B = Generator_S2F(input_nc, output_nc).to(device)\n","  netG_B2A = Generator_F2S(input_nc, output_nc).to(device)\n","\n","\n","  # load latest checkpoint\n","  netG_A2B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_A2B.pth')))\n","  netG_B2A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_B2A.pth')))\n","\n","  # turn the validation mode\n","  netG_A2B.eval()\n","  netG_B2A.eval()\n","\n","  # input tensors\n","  Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n","  input_A = Tensor(batch_size, input_nc, image_size, image_size, 3)\n","  input_B = Tensor(batch_size, output_nc, image_size, image_size, 3)\n","\n","  # input transformations\n","  img_transforms = transforms.Compose([\n","                                       transforms.Resize((image_size, image_size), interpolation=Image.BICUBIC),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((.5,.5,.5),(.5,.5,.5))\n","  ])\n","  to_pil = transforms.ToPILImage()\n","\n","  image_queue = QueueMask(length=mask_queue_size)\n","  for i,(path_A, path_B) in enumerate(zip(A_paths, B_paths)):\n","    image_A = Image.open(path_A).convert(\"RGB\")\n","    image_B = Image.open(path_A).convert(\"RGB\")\n","\n","    im_A = (img_transforms(image_A).unsqueeze(0)).to(device)\n","    im_B = (img_transforms(image_B).unsqueeze(0)).to(device)\n","\n","    \n","    # Image.fromarray(np.array(transforms.Resize((image_size, image_size))(image_A))).save(os.path.join(save_path, 'A', 'A_{}.jpg'.format(i)))\n","    # Image.fromarray(np.array(transforms.Resize((image_size, image_size))(image_B))).save(os.path.join(save_path, 'B', 'B_{}.jpg'.format(i)))\n","\n","    # generate A -> B\n","    A_B = netG_A2B(im_A)\n","    w,h = image_A.size\n","\n","    current_mask = mask_generator(A_B, im_A)\n","    image_queue.insert(current_mask)\n","    A_B = .5 * (A_B + 1)\n","    A_B = np.array((to_pil(A_B.data.squeeze(0).cpu())))\n","    Image.fromarray(A_B).save(os.path.join(save_path, 'A_B', 'A_B_{}.jpg'.format(i)))\n","\n","    # generate B -> A\n","    mask = image_queue.rand_item()\n","    B_A = netG_B2A(im_B, mask)\n","    w,h = image_B.size\n","\n","    B_A = .5 * (B_A + 1)\n","    B_A = np.array((to_pil(B_A.data.squeeze(0).cpu())))\n","    Image.fromarray(B_A).save(os.path.join(save_path, 'B_A', 'B_A_{}.jpg'.format(i)))\n","\n","    mask_cpu = np.array((to_pil(.5 * (current_mask.data + 1).squeeze(0).cpu())))\n","    Image.fromarray(mask_cpu).save(os.path.join(save_path, 'masks', 'mask_{}.jpg'.format(i)))\n","\n","  print(\"---- Inference finished. Time : {} ----\".format(time.time() - start_time).upper())\n","  return image_queue\n","\n","\n","def save_images(image_paths, save_path, domain):\n","  try:\n","    os.mkdir(save_path)\n","  except:\n","    pass\n","\n","  for i in range(len(image_paths)):\n","    img = plt.imread(image_paths[i])\n","    plt.imsave(os.path.join(save_path,'{}_{}.jpg'.format(domain, i)), img)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hXJjtqf5IL_o","colab_type":"text"},"source":["### Train"]},{"cell_type":"code","metadata":{"id":"JOpXykMJIK_a","colab_type":"code","colab":{}},"source":["checkpoint_dir = 'mask_shadow_gan/output/checkpoints/checkpoints_v0.1.1/1/'\n","images_dir = 'mask_shadow_gan/output/images/images_v0.1.1/1/'\n","summary_dir = 'mask_shadow_gan/output/summary/summary_v0.1.1/1/'\n","root_dir = 'data/ISTD_Dataset/'\n","\n","# validation pathes\n","A_dir_inf = 'mask_shadow_gan/output/results/test_set_meta/test_paths/ISTD/shadow_path.pickle'\n","B_dir_inf = 'mask_shadow_gan/output/results/test_set_meta/test_paths/ISTD/free_path.pickle'\n","results_dir = 'mask_shadow_gan/output/results/v.0.1.1/1'\n","\n","\n","\n","load_model = True\n","batch_size=1\n","image_size=256\n","ngf=64\n","ndf=64\n","\n","lambda1=10\n","lambda2=10\n","identity_lambda = 0.5\n","learning_rate=2e-4\n","lr_D = 4e-4  # TTUR\n","lr_G = 1e-4  # TTUR\n","\n","beta1=.5\n","mask_queue_size=50\n","slope=0.2\n","stddev=0.02\n","\n","input_nc=3\n","output_nc=3\n","\n","n_res_blocks=9\n","dilation_factors = [1,1,1,2,4,8,16,1,1]\n","REAL_LABEL=0.9  # label smoothing\n","reduction_factor=4\n","\n","device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","n_epochs=202\n","decay_epoch=100\n","epoch=0\n","img_snapshot=500\n","model_snapshot=5\n","log_snapshot=10\n","\n","coef_identity = 5\n","coef_cycle = 10\n","coef_adv = 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kInJrx7r1F7L","colab_type":"code","colab":{}},"source":["class MaskShadowGAN(object):\n","  def __init__(self):\n","    pass\n","\n","  def build(self):\n","    ###### Definition of variables ######\n","    # Networks\n","    print(f\"------------------- Definition of variables -------------------\")\n","    \n","    self.netG_A2B = Generator_S2F(input_nc, output_nc, \n","                                  n_residual_blocks=n_res_blocks,\n","                                  dilation_factors=dilation_factors,\n","                                  reduction=reduction_factor)  # shadow to shadow_free\n","    self.netG_B2A = Generator_F2S(output_nc, input_nc,\n","                                  n_residual_blocks=n_res_blocks,\n","                                  dilation_factors=dilation_factors,\n","                                  reduction=reduction_factor)  # shadow_free to shadow\n","    self.netD_A = Discriminator(input_nc)\n","    self.netD_B = Discriminator(output_nc)\n","\n","\n","    self.netG_A2B.cuda()\n","    self.netG_B2A.cuda()\n","    self.netD_A.cuda()\n","    self.netD_B.cuda()\n","\n","    self.netG_A2B.apply(weights_init_normal)\n","    self.netG_B2A.apply(weights_init_normal)\n","    self.netD_A.apply(weights_init_normal)\n","    self.netD_B.apply(weights_init_normal)\n","\n","    # Lossess\n","    self.criterion_GAN = torch.nn.MSELoss()  # lsgan\n","    # criterion_GAN = torch.nn.BCEWithLogitsLoss() #vanilla\n","    self.criterion_cycle = torch.nn.L1Loss()\n","    self.criterion_identity = torch.nn.L1Loss()\n","\n","    # Optimizers & LR schedulers\n","    self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A2B.parameters(), self.netG_B2A.parameters()),\n","                    lr=lr_G, betas=(0.5, 0.999))\n","    self.optimizer_D_A = torch.optim.Adam(self.netD_A.parameters(), lr=lr_D, betas=(0.5, 0.999))\n","    self.optimizer_D_B = torch.optim.Adam(self.netD_B.parameters(), lr=lr_D, betas=(0.5, 0.999))\n","\n","    self.lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(self.optimizer_G,\n","                              lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n","    self.lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(self.optimizer_D_A,\n","                              lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n","    self.lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(self.optimizer_D_B,\n","                              lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n","    \n","    Tensor = torch.cuda.FloatTensor\n","    self.input_A = Tensor(batch_size, input_nc, image_size, image_size)\n","    self.input_B = Tensor(batch_size, output_nc, image_size, image_size)\n","    self.target_real = Variable(Tensor(batch_size).fill_(REAL_LABEL), requires_grad=False)\n","    self.target_fake = Variable(Tensor(batch_size).fill_(0.0), requires_grad=False)\n","    self.mask_non_shadow = Variable(Tensor(batch_size, 1, image_size, image_size).fill_(-1.0), requires_grad=False) #-1.0 non-shadow\n","\n","    self.fake_A_buffer = ReplayBuffer()\n","    self.fake_B_buffer = ReplayBuffer()\n","\n","    # Dataset loader\n","    self.transforms_ = [\n","            transforms.Resize(int(image_size * 1.12), Image.BICUBIC),\n","            transforms.RandomCrop(image_size),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n","\n","    self.dataloader = DataLoader(ImageDataset(root_dir, transforms_=self.transforms_),\n","                                              batch_size=batch_size, shuffle=True, num_workers=1)\n","\n","    \"\"\"Summary writing to tensorboard\"\"\"\n","    self.writer = SummaryWriter(log_dir=summary_dir)\n","    return self\n","    \n","\n","  def train(self):\n","    step = 0\n","    epoch = 0\n","    if load_model:\n","      print(\"Resume training\")\n","      epoch, step = self.load_model()\n","      # epoch+=1\n","\n","    to_pil = transforms.ToPILImage()\n","    mask_queue =  QueueMask(self.dataloader.__len__()/4)\n","\n","    ###### Training ######\n","    print(f\"------------------- Start Training -------------------\")\n","    epoch_cp = epoch\n","    try:\n","      for ep in tqdm_notebook(range(epoch, n_epochs), total=n_epochs-epoch):\n","        for i, _batch in enumerate(self.dataloader):\n","          # Set model input\n","          batch = _batch['result']\n","          time_batch = _batch['time']\n","          real_A = Variable(self.input_A.copy_(batch['A']))\n","          real_B = Variable(self.input_B.copy_(batch['B']))\n","\n","          ###### Generators A2B and B2A ######\n","          start_time = time.time()\n","          self.optimizer_G.zero_grad()\n","\n","          # Identity loss\n","          # G_A2B(B) should equal B if real B is fed\n","          same_B = self.netG_A2B(real_B)\n","          loss_identity_B = self.criterion_identity(same_B, real_B)  # ||Gb(b)-b||1\n","          # G_B2A(A) should equal A if real A is fed, so the mask should be all zeros\n","          same_A = self.netG_B2A(real_A, self.mask_non_shadow)\n","          loss_identity_A = self.criterion_identity(same_A, real_A)  # ||Ga(a)-a||1\n","\n","          # GAN loss\n","          fake_B = self.netG_A2B(real_A)\n","          pred_fake = self.netD_B(fake_B)\n","          loss_GAN_A2B = self.criterion_GAN(pred_fake, self.target_real)  # log(Db(Gb(a)))\n","\n","          mask_queue.insert(mask_generator(real_A, fake_B))\n","\n","          fake_A = self.netG_B2A(real_B, mask_queue.rand_item())\n","          pred_fake = self.netD_A(fake_A)\n","          loss_GAN_B2A = self.criterion_GAN(pred_fake, self.target_real)  # log(Da(Ga(b)))\n","\n","          # Cycle loss\n","          recovered_A = self.netG_B2A(fake_B, mask_queue.last_item()) # real shadow, false shadow free\n","          loss_cycle_ABA = self.criterion_cycle(recovered_A, real_A) * 10.0  # ||Ga(Gb(a))-a||1\n","\n","          recovered_B = self.netG_A2B(fake_A)\n","          loss_cycle_BAB = self.criterion_cycle(recovered_B, real_B) * 10.0  # ||Gb(Ga(b))-b||1\n","\n","          # Total loss\n","          loss_G = coef_identity * (loss_identity_A + loss_identity_B) + \\\n","            coef_adv * (loss_GAN_A2B + loss_GAN_B2A) + coef_cycle * (loss_cycle_ABA + loss_cycle_BAB)\n","\n","          time_G_forward = time.time() - start_time\n","\n","          start_time = time.time()\n","          loss_G.backward()\n","          self.optimizer_G.step()\n","          time_G_backward = time.time() - start_time\n","\n","          ###################################\n","\n","          ###### Discriminator A ######\n","          start_time = time.time()\n","          self.optimizer_D_A.zero_grad()\n","\n","          # Real loss\n","          pred_real = self.netD_A(real_A)\n","          loss_D_real = self.criterion_GAN(pred_real, self.target_real)  # log(Da(a))\n","\n","          # Fake loss\n","          fake_A = self.fake_A_buffer.push_and_pop(fake_A)\n","          pred_fake = self.netD_A(fake_A.detach())\n","          loss_D_fake = self.criterion_GAN(pred_fake, self.target_fake)  # log(1-Da(G(b)))\n","\n","          # Total loss\n","          loss_D_A = (loss_D_real + loss_D_fake) * 0.5 * coef_adv\n","          time_DA_forward = time.time() - start_time\n","          \n","          start_time = time.time()\n","          loss_D_A.backward()\n","\n","          self.optimizer_D_A.step()\n","          time_DA_backward = time.time() - start_time\n","\n","          ###################################\n","\n","          ###### Discriminator B ######\n","          start_time = time.time()\n","          self.optimizer_D_B.zero_grad()\n","\n","          # Real loss\n","          pred_real = self.netD_B(real_B)\n","          loss_D_real = self.criterion_GAN(pred_real, self.target_real)  # log(Db(b))\n","\n","          # Fake loss\n","          fake_B = self.fake_B_buffer.push_and_pop(fake_B)\n","          pred_fake = self.netD_B(fake_B.detach())\n","          loss_D_fake = self.criterion_GAN(pred_fake, self.target_fake)  # log(1-Db(G(a)))\n","\n","          # Total loss\n","          loss_D_B = (loss_D_real + loss_D_fake) * 0.5 * coef_adv\n","          time_DB_forward = time.time() - start_time\n","\n","          start_time = time.time()\n","\n","          loss_D_B.backward()\n","          self.optimizer_D_B.step()\n","\n","          time_DB_backward = time.time() - start_time\n","          ###################################\n","\n","          step += 1\n","          if step % img_snapshot == 0:\n","            img_fake_A = 0.5 * (fake_A.detach().data + 1.0)\n","            img_fake_A = (to_pil(img_fake_A.data.squeeze(0).cpu()))\n","            img_fake_A.save(os.path.join(images_dir, f\"fake_A_{step}.png\"))\n","\n","            img_fake_B = 0.5 * (fake_B.detach().data + 1.0)\n","            img_fake_B = (to_pil(img_fake_B.data.squeeze(0).cpu()))\n","            img_fake_B.save(os.path.join(images_dir, f\"fake_B_{step}.png\"))\n","\n","          # logging\n","          if step % log_snapshot == 0:\n","            self.writer.add_scalar('G/GAN_A2B', loss_GAN_A2B, global_step=step)\n","            self.writer.add_scalar('G/GAN_B2A', loss_GAN_B2A, global_step=step)\n","            self.writer.add_scalar('G/cycle_ABA', loss_cycle_ABA, global_step=step)\n","            self.writer.add_scalar('G/cycle_BAB', loss_cycle_BAB, global_step=step)\n","            self.writer.add_scalar('G/idt_A', loss_identity_A, global_step=step)\n","            self.writer.add_scalar('G/idt_B', loss_identity_B, global_step=step)\n","\n","            self.writer.add_scalar('D/D_A', loss_D_A, global_step=step)\n","            self.writer.add_scalar('D/D_B', loss_D_B, global_step=step)\n","\n","            self.writer.add_scalar('T/batch', time_batch, global_step=step)\n","            self.writer.add_scalar('T/G_forward', time_G_forward, global_step=step)\n","            self.writer.add_scalar('T/G_backward', time_G_backward, global_step=step)\n","\n","            self.writer.add_scalar('T/D_A_forward', time_DA_forward, global_step=step)\n","            self.writer.add_scalar('T/D_A_backward', time_DA_backward, global_step=step)\n","\n","            self.writer.add_scalar('T/D_B_forward', time_DB_forward, global_step=step)\n","            self.writer.add_scalar('T/D_B_backward', time_DB_backward, global_step=step)\n","\n","\n","          \n","\n","        # Update learning rates\n","        self.lr_scheduler_G.step()\n","        self.lr_scheduler_D_A.step()\n","        self.lr_scheduler_D_B.step()\n","\n","\n","        # Save models checkpoints\n","        if ep % model_snapshot == 0:\n","          print(f\"Save model -- epoch: {ep}, step: {step}\")\n","          self.save_model(ep, step)\n","\n","          print('Run validation...')\n","          save_test(A_dir_inf, B_dir_inf, os.path.join(results_dir, f'msg_{ep}'))\n","\n","        epoch_cp = ep\n","\n","\n","    except Exception as e:\n","      raise e\n","    finally:\n","      print(f\"Save model -- epoch: {epoch_cp}, step: {step}\")\n","      self.save_model(epoch_cp, step)\n","\n","\n","\n","  def save_model(self, epoch_num, step):\n","    np.savetxt(os.path.join(checkpoint_dir, 'epoch_num.txt'), [epoch_num])\n","    np.savetxt(os.path.join(checkpoint_dir, 'step.txt'), [step])\n","\n","    torch.save(self.netG_A2B.state_dict(), os.path.join(checkpoint_dir, 'netG_A2B.pth'))\n","    torch.save(self.netG_B2A.state_dict(), os.path.join(checkpoint_dir, 'netG_B2A.pth'))\n","    torch.save(self.netD_A.state_dict(), os.path.join(checkpoint_dir, 'netD_A.pth'))\n","    torch.save(self.netD_B.state_dict(), os.path.join(checkpoint_dir, 'netD_B.pth'))\n","\n","    torch.save(self.optimizer_G.state_dict(), os.path.join(checkpoint_dir, 'optimizer_G.pth'))\n","    torch.save(self.optimizer_D_A.state_dict(), os.path.join(checkpoint_dir, 'optimizer_D_A.pth'))\n","    torch.save(self.optimizer_D_B.state_dict(), os.path.join(checkpoint_dir, 'optimizer_D_B.pth'))\n","\n","    torch.save(self.lr_scheduler_G.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_G.pth'))\n","    torch.save(self.lr_scheduler_D_A.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_D_A.pth'))\n","    torch.save(self.lr_scheduler_D_B.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_D_B.pth'))\n","\n","\n","  def load_model(self):\n","    epoch = int(np.loadtxt(os.path.join(checkpoint_dir, 'epoch_num.txt')))\n","    step  = int(np.loadtxt(os.path.join(checkpoint_dir, 'step.txt')))\n","    \n","    self.netG_A2B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_A2B.pth')))\n","    self.netG_B2A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_B2A.pth')))\n","    self.netD_A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netD_A.pth')))\n","    self.netD_B.load_state_dict(torch.load((os.path.join(checkpoint_dir, 'netD_B.pth'))))\n","\n","    self.optimizer_G.load_state_dict(torch.load((os.path.join(checkpoint_dir, 'optimizer_G.pth'))))\n","    self.optimizer_D_A.load_state_dict(torch.load((os.path.join(checkpoint_dir, 'optimizer_D_A.pth'))))\n","    self.optimizer_D_B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'optimizer_D_B.pth')))\n","\n","    self.lr_scheduler_G.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'lr_scheduler_G.pth')))\n","    self.lr_scheduler_D_A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'lr_scheduler_D_A.pth')))\n","    self.lr_scheduler_D_B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'lr_scheduler_D_B.pth')))\n","    print(f\"Model loaded -- {epoch}:{step}\")\n","    return epoch, step\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6OA37Kg-bSj","colab_type":"code","outputId":"31fbe1c4-2cc2-4057-c055-9fdb96964c6e","executionInfo":{"status":"ok","timestamp":1584364911718,"user_tz":-120,"elapsed":22031,"user":{"displayName":"Владислав Андроник","photoUrl":"","userId":"15929840215236502543"}},"colab":{"base_uri":"https://localhost:8080/","height":81}},"source":["model = MaskShadowGAN().build()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["------------------- Definition of variables -------------------\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"jRM6TxxT-e9t","colab_type":"code","outputId":"fad985a0-bcba-40f5-9ea5-bef37048c2b9","executionInfo":{"status":"ok","timestamp":1584338177154,"user_tz":-120,"elapsed":15603615,"user":{"displayName":"Владислав Андроник","photoUrl":"","userId":"15929840215236502543"}},"colab":{"base_uri":"https://localhost:8080/","height":155,"referenced_widgets":["d4d9d62dbdf7462091157acf55ba10d7","6c96ba10f6bf4706bed7accb7a5ee63b","e0fa50b42d01498c9e51a4c5614f6f45","3d1af278db0744e7a76cad8063c670a7","a50dcecf117d44e0825c80639933cdb2","ceefaef75b0b48afb01a2ee9342810c8","f8636826d23e45ec86bbb6d9b303623e","a83a9de6559c4b8baad9b1468df1b6c0"]}},"source":["# turn on save\n","model.train()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Resume training\n","Model loaded -- 199:283402\n","------------------- Start Training -------------------\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4d9d62dbdf7462091157acf55ba10d7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FT4m4PQZNZRG","colab_type":"code","colab":{}},"source":["\"\"\"function preventFromOff(){\n","  console.log(\"Click button\");\n","  document.querySelector(\"colab-connect-button\").shadowRoot.getElementById(\"connect\").click()\n","}\n","var timeout = 8 * 60 * 60 * 1000;\n","var delay = 3 * 60 * 1000;\n","var refreshId = setInterval(preventFromOff, delay);\n","setTimeout(() => {clearInterval(refreshId); console.log(\"Stopped script\");}, timeout);\"\"\""],"execution_count":0,"outputs":[]}]}