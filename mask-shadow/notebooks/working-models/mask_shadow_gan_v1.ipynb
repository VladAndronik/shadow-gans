{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8KdB0MiJsn4q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import init\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from PIL import Image\n",
    "import functools\n",
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xUCwdN5yJ56"
   },
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aLvS3B_G2pn_"
   },
   "outputs": [],
   "source": [
    "def init_weights(net, stddev=.02):\n",
    "\n",
    "  def weights_initializer(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "      init.normal_(m.weight.data, mean=0.0, std=stddev)\n",
    "\n",
    "      if hasattr(m, 'bias') and m.bias is not None:\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "  net.apply(weights_initializer)\n",
    "  return net\n",
    "\n",
    "\n",
    "def init_net(net, device, stddev=0.02):\n",
    "  net.to(device)\n",
    "  init_weights(net, stddev=stddev)\n",
    "  return net\n",
    "\n",
    "\n",
    "def build_generator(input_nc, device, n_blocks=9, ngf=64, stddev=0.02):\n",
    "  model = ResNetGenerator(input_nc, n_blocks=n_blocks, ngf=ngf)\n",
    "  return init_net(model, device=device, stddev=stddev)\n",
    "\n",
    "def build_discriminator(input_nc, device, ndf=64, stddev=0.02, slope=.2):\n",
    "  model = Disriminator(input_nc, ndf=ndf, slope=slope)\n",
    "  return init_net(model, device=device, stddev=stddev)\n",
    "\n",
    "\n",
    "class Generator_S2F(nn.Module):\n",
    "  def __init__(self, input_nc, n_blocks=9, ngf=64):\n",
    "    super(Generator_S2F, self).__init__()\n",
    "\n",
    "    # c7s1_k\n",
    "    model = [nn.ReflectionPad2d(3),\n",
    "             nn.Conv2d(input_nc, ngf, 7, stride=1, padding=0),\n",
    "             nn.InstanceNorm2d(ngf),\n",
    "             nn.ReLU(inplace=True)]\n",
    "    # 2x downsample\n",
    "    model += [nn.Conv2d(ngf, ngf * 2, 3, stride=2, padding=1),\n",
    "              nn.InstanceNorm2d(ngf * 2),\n",
    "              nn.ReLU(True)]\n",
    "\n",
    "    model += [nn.Conv2d(ngf * 2, ngf * 4, 3, stride=2, padding=1),\n",
    "              nn.InstanceNorm2d(ngf * 4),\n",
    "              nn.ReLU(True)]\n",
    "\n",
    "    # resnet blocks\n",
    "    for n in range(n_blocks):\n",
    "      model += [ResNetBlock(ngf * 4, ngf * 4)]\n",
    "\n",
    "    # 2x upsampling\n",
    "    model += [nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, stride=2, padding=1, \n",
    "                                 output_padding=1),\n",
    "              nn.InstanceNorm2d(ngf * 2),\n",
    "              nn.ReLU(True)]\n",
    "\n",
    "    model += [nn.ConvTranspose2d(ngf * 2, ngf, 3, stride=2, padding=1, \n",
    "                                 output_padding=1),\n",
    "              nn.InstanceNorm2d(ngf),\n",
    "              nn.ReLU(True)]\n",
    "\n",
    "    \n",
    "    # c7s1_3\n",
    "    model += [nn.ReflectionPad2d(3),\n",
    "              nn.Conv2d(ngf, 3, 7, padding=0, stride=1)]\n",
    "\n",
    "    self.model = nn.Sequential(*model)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return (self.model(x) + x).tanh()\n",
    "\n",
    "class Generator_F2S(nn.Module):\n",
    "  def __init__(self, input_nc, output_nc, ngf=64, n_blocks=9):\n",
    "    super(Generator_F2S, self).__init__()\n",
    "    \n",
    "    # c7s1_k\n",
    "    model = [nn.ReflectionPad2d(3),\n",
    "             nn.Conv2d(input_nc, ngf, 7, stride=1, padding=0),\n",
    "             nn.InstanceNorm2d(ngf),\n",
    "             nn.ReLU(inplace=True)]\n",
    "    # 2x downsample\n",
    "    model += [nn.Conv2d(ngf, ngf * 2, 3, stride=2, padding=1),\n",
    "              nn.InstanceNorm2d(ngf * 2),\n",
    "              nn.ReLU(True)]\n",
    "\n",
    "    model += [nn.Conv2d(ngf * 2, ngf * 4, 3, stride=2, padding=1),\n",
    "              nn.InstanceNorm2d(ngf * 4),\n",
    "              nn.ReLU(True)]\n",
    "\n",
    "    # resnet blocks\n",
    "    for n in range(n_blocks):\n",
    "      model += [ResNetBlock(ngf * 4, ngf * 4)]\n",
    "\n",
    "    # 2x upsampling\n",
    "    model += [nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, stride=2, padding=1, \n",
    "                                 output_padding=1),\n",
    "              nn.InstanceNorm2d(ngf * 2),\n",
    "              nn.ReLU(True)]\n",
    "\n",
    "    model += [nn.ConvTranspose2d(ngf * 2, ngf, 3, stride=2, padding=1, \n",
    "                                 output_padding=1),\n",
    "              nn.InstanceNorm2d(ngf),\n",
    "              nn.ReLU(True)]\n",
    "\n",
    "    \n",
    "    # c7s1_3\n",
    "    model += [nn.ReflectionPad2d(3),\n",
    "              nn.Conv2d(ngf, 3, 7, padding=0, stride=1)]\n",
    "\n",
    "    self.model = nn.Sequential(*model)\n",
    "\n",
    "  def forward(self, x, mask):\n",
    "    gen = self.model(torch.cat((x, mask), 1))\n",
    "    return (gen + x).tanh()\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "  def __init__(self, input_nc, output_nc, use_bias=True):\n",
    "    super(ResNetBlock, self).__init__()\n",
    "\n",
    "    model  = [nn.ReflectionPad2d(1),\n",
    "              nn.Conv2d(input_nc, output_nc, 3, bias=use_bias),\n",
    "              nn.InstanceNorm2d(output_nc),\n",
    "              nn.ReLU(True)]\n",
    "\n",
    "    \n",
    "    model += [nn.ReflectionPad2d(1),\n",
    "              nn.Conv2d(input_nc, output_nc, 3, bias=use_bias),\n",
    "              nn.InstanceNorm2d(output_nc),\n",
    "              nn.ReLU(True)]\n",
    "    \n",
    "    self.conv_block = nn.Sequential(*model)\n",
    "  \n",
    "  def forward(self, input):\n",
    "    output = input + self.conv_block(input)\n",
    "    return output\n",
    "\n",
    "\n",
    "class Disriminator(nn.Module):\n",
    "  # WARNING: Implemented 94x94 Patch Discriminator.\n",
    "  def __init__(self, input_nc, ndf=64, slope=.2):\n",
    "    super(Disriminator, self).__init__()\n",
    "    model = [\n",
    "             nn.Conv2d(input_nc, ndf, 4, stride=2, padding=1, bias=True),\n",
    "             nn.LeakyReLU(slope, True)\n",
    "    ]\n",
    "\n",
    "    model += [\n",
    "             nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1),\n",
    "             nn.InstanceNorm2d(ndf * 4),\n",
    "             nn.LeakyReLU(slope, inplace=True),\n",
    "\n",
    "             nn.Conv2d(ndf *2, ndf * 4, 4, stride=2, padding=1),\n",
    "             nn.InstanceNorm2d(ndf * 4),\n",
    "             nn.LeakyReLU(slope, inplace=True),\n",
    "\n",
    "             # Use of ReflectionPadding and bias=False from orig. impl.\n",
    "             # nn.Conv2d(ndf * 4, ndf * 8, stride=1, padding=1) -- must stride=1\n",
    "             nn.Conv2d(ndf * 4, ndf * 8, 4, stride=2, padding=1),\n",
    "             nn.InstanceNorm2d(ndf * 8),\n",
    "             nn.LeakyReLU(slope, inplace=True)\n",
    "    ]\n",
    "\n",
    "    model += [\n",
    "              nn.Conv2d(ndf * 8, 1, 4, stride=1, padding=1)\n",
    "    ]\n",
    "\n",
    "    self.model = nn.Sequential(*model)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dapB9uu322VG"
   },
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "  def __init__(self, device, real_target_label=1.0, fake_target_label=0.0):\n",
    "    super(GANLoss, self).__init__()\n",
    "    self.loss = nn.MSELoss()\n",
    "    self.register_buffer('real_label', torch.tensor(real_target_label))\n",
    "    self.register_buffer('fake_label', torch.tensor(fake_target_label))\n",
    "    self.device = device\n",
    "\n",
    "\n",
    "  def get_target_tensor(self, prediction, target_is_real):\n",
    "    if target_is_real:\n",
    "      target_tensor = self.real_label\n",
    "    else:\n",
    "      target_tensor = self.fake_label\n",
    "\n",
    "    return target_tensor.expand_as(prediction)\n",
    "\n",
    "  def __call__(self, prediction, target_is_real):\n",
    "    target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
    "    loss = self.loss(prediction, target_tensor.to(self.device))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5253,
     "status": "ok",
     "timestamp": 1580411239842,
     "user": {
      "displayName": "Vlad Andronik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKTHOk9ud4cZtCOV8G0IGkRw4LOUbSfAFI8aQG8A=s64",
      "userId": "00447066830077822735"
     },
     "user_tz": -120
    },
    "id": "EwVsx-0O0WSI",
    "outputId": "e9b9896f-49a1-456b-ffb1-962a567abc18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Summary models ----\n",
      "Number of parameters (in millions):\n",
      "D         G         Overall             \n",
      "11.058    45.512    56.57               \n"
     ]
    }
   ],
   "source": [
    "# summary of the models\n",
    "def num_params(model):\n",
    "  model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "  params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "  return params\n",
    "\n",
    "dL = Disriminator(3)\n",
    "g = Generator_S2F(3)\n",
    "\n",
    "d_num = round(num_params(dL) * 2 / 1e6, 3) * 2\n",
    "g_num = round(num_params(g) * 2 / 1e6, 3) * 2\n",
    "overall = round(d_num + g_num, 3)\n",
    "\n",
    "print('---- Summary models ----')\n",
    "print(\"Number of parameters (in millions):\")\n",
    "print(\"{:10}{:10}{:20}\".format(\"D\", 'G', \"Overall\"))\n",
    "print(\"{:10}{:10}{:20}\".format(str(d_num), str(g_num), str(overall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qa176fMmCqWx"
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "M2ZejQrA4swR"
   },
   "outputs": [],
   "source": [
    "class UnalignedDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, A_dir, B_dir, image_size):\n",
    "    self.A_paths = sorted(glob.glob(os.path.join(A_dir, '*.jpg')))\n",
    "    self.B_paths = sorted(glob.glob(os.path.join(B_dir, '*.jpg')))\n",
    "\n",
    "    self.A_size = len(self.A_paths)\n",
    "    self.B_size = len(self.B_paths)\n",
    "\n",
    "    self.image_size=image_size\n",
    "    self.transform_A = self.get_transform()\n",
    "    self.transform_B = self.get_transform()\n",
    "\n",
    "  def __getitem__(self, index_A):\n",
    "    index_B = random.randint(0, self.B_size-1)\n",
    "    A_path = self.A_paths[index_A % self.A_size]\n",
    "    B_path = self.B_paths[index_B]\n",
    "\n",
    "    A_img = Image.open(A_path).convert('RGB')\n",
    "    B_img = Image.open(B_path).convert('RGB')\n",
    "\n",
    "    A = self.transform_A(A_img)\n",
    "    B = self.transform_B(B_img)\n",
    "\n",
    "\n",
    "    return {'A':A, 'B':B, 'A_path':A_path, 'B_path':B_path}\n",
    "\n",
    "    \n",
    "  def __len__(self):\n",
    "    return max(self.A_size, self.B_size)\n",
    "\n",
    "\n",
    "  def get_transform(self):\n",
    "    transform_list = [\n",
    "                      transforms.Resize(int(self.image_size * 1.12), Image.BICUBIC),\n",
    "                      transforms.RandomCrop(self.image_size),\n",
    "                      transforms.RandomHorizontalFlip(),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    "    return transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2OVbEOT-D0jx"
   },
   "source": [
    "### Pool,queue,sheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yau_WIsOD813"
   },
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "  def __init__(self, pool_size):\n",
    "    self.pool_size=pool_size\n",
    "    self.images = []\n",
    "\n",
    "  def sample(self, image_data):\n",
    "    if len(self.images) < self.pool_size:\n",
    "      self.images.append(image_data)\n",
    "      return image_data\n",
    "    \n",
    "    p = random.random()\n",
    "    if p > 0.5:\n",
    "      idx = random.randrange(0, self.pool_size)\n",
    "      tmp_data = self.images[idx].clone()\n",
    "      self.images[idx] = image_data.clone()\n",
    "      return tmp_data\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NgxPccVKELEx"
   },
   "outputs": [],
   "source": [
    "class QueueMask():\n",
    "  def __init__(self, queue_size):\n",
    "    self.queue_size=queue_size\n",
    "    self.queue = []\n",
    "\n",
    "  def insert(self, mask):\n",
    "    if len(self.queue) >= self.queue_size:\n",
    "      self.queue.pop(0)\n",
    "\n",
    "    self.queue.append(mask)\n",
    "  \n",
    "  def rand_item(self):\n",
    "    assert len(self.queue) > 0, 'Error! Empty queue.'\n",
    "    return self.queue[random.randint(0, len(self.queue) - 1)]\n",
    "\n",
    "  def last_item(self):\n",
    "    assert len(self.queue) > 0, 'Error! Empty queue.'\n",
    "    return self.queue[len(self.queue) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zP4xe4hBva6v"
   },
   "outputs": [],
   "source": [
    "class LambdaLR():\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR_LQGCkodau"
   },
   "source": [
    "### Mask generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "t9gVuc-KoqO5"
   },
   "outputs": [],
   "source": [
    "to_pil = transforms.ToPILImage()\n",
    "to_gray = transforms.Grayscale(num_output_channels=1)\n",
    "\n",
    "def mask_generator(shadow, shadow_free):\n",
    "  shadow_gray = to_gray(to_pil( ((shadow.data.squeeze(0) + 1) * .5).cpu()) )\n",
    "  shadow_free_gray = to_gray(to_pil(((shadow_free.data.squeeze(0) + 1) * .5).cpu()))\n",
    "  diff = np.asarray(shadow_free_gray, dtype='float32') - np.asarray(shadow_gray, dtype='float32')\n",
    "\n",
    "  T = threshold_otsu(diff)\n",
    "  mask = torch.tensor((np.float32(diff >= T) - .5) / .5).unsqueeze(0).unsqueeze(0).cuda()\n",
    "  mask.requires_grad = False\n",
    "\n",
    "  return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjGTTjN7qXOT"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ccx8LnfJxMEl"
   },
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_dir = 'mask_shadow_gan/output/checkpoints_v1/'\n",
    "images_dir = 'mask_shadow_gan/output/images_v1/'\n",
    "summary_dir = 'mask_shadow_gan/output/summary_v1/'\n",
    "\n",
    "A_dir = 'data/shadow_USR/shadow_train/'\n",
    "B_dir = 'data/shadow_USR/shadow_free/'\n",
    "\n",
    "\n",
    "load_model = True\n",
    "batch_size=1\n",
    "image_size=256\n",
    "ngf=64\n",
    "ndf=64\n",
    "\n",
    "lambda1=10\n",
    "lambda2=10\n",
    "identity_lambda = 0.5\n",
    "learning_rate=2e-4\n",
    "beta1=.5\n",
    "pool_size=50\n",
    "mask_queue_size=50\n",
    "n_blocks=9 if image_size==256 else 6\n",
    "slope=0.2\n",
    "stddev=0.02\n",
    "\n",
    "input_nc=3\n",
    "output_nc=3\n",
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "real_label=1.\n",
    "\n",
    "n_epochs=200\n",
    "decay_start=100\n",
    "offset=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_9Rn0jHfdIvm"
   },
   "outputs": [],
   "source": [
    "def get_step(filename):\n",
    "  match = re.findall(r'(\\d+).pth', filename)[0]\n",
    "  return int(match)\n",
    "\n",
    "def latest_checkpoint_files(check_dir, f):\n",
    "  return max(map(f, os.listdir(check_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SVRY4MvpvVBF"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "  ### Definition of variables ###\n",
    "  print(\"---- Define the networks ----\".upper())\n",
    "  # Networks\n",
    "  netG_A2B = Generator_S2F(input_nc, n_blocks=n_blocks, ngf=ngf)\n",
    "  netG_B2A = Generator_F2S(input_nc+1, output_nc, n_blocks=n_blocks, ngf=ngf)\n",
    "  netD_B = Disriminator(input_nc, ndf=ndf, slope=slope)\n",
    "  netD_A = Disriminator(input_nc, ndf=ndf, slope=slope)\n",
    "\n",
    "  # initializing the nets and transferring to gpu\n",
    "  print(\"---- Initializing the networks ----\".upper())\n",
    "  init_net(netG_A2B, device, stddev=stddev)\n",
    "  init_net(netG_B2A, device, stddev=stddev)\n",
    "  init_net(netD_B, device, stddev=stddev)\n",
    "  init_net(netD_A, device, stddev=stddev)\n",
    "\n",
    "  # Losses\n",
    "  print(\"---- Define the losses ----\".upper())\n",
    "  criterion_GAN = torch.nn.MSELoss()\n",
    "  criterion_cycle = torch.nn.L1Loss()\n",
    "  criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "  # Shedulers and Optimizers\n",
    "  print(\"---- Define the schedulers and optimizers ----\".upper())\n",
    "  optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), \n",
    "                                 betas=(beta1, 0.999), lr=learning_rate)\n",
    "  optimizer_D_A = torch.optim.Adam(netD_A.parameters(), \n",
    "                                 betas=(beta1, 0.999), lr=learning_rate)\n",
    "  \n",
    "  optimizer_D_B = torch.optim.Adam(netD_B.parameters(), \n",
    "                                 betas=(beta1, 0.999), lr=learning_rate)\n",
    "\n",
    "  lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G,\n",
    "                                                    lr_lambda=LambdaLR(n_epochs, offset, decay_start).step)\n",
    "  lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A,\n",
    "                                                    lr_lambda=LambdaLR(n_epochs, offset, decay_start).step)\n",
    "  lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B,\n",
    "                                                    lr_lambda=LambdaLR(n_epochs, offset, decay_start).step)\n",
    "  \n",
    "  # Resume training - loading the state dicts\n",
    "  latest_step = 0\n",
    "  if load_model:\n",
    "    print(\"---- Resume training from the latest checkpoint ----\".upper())\n",
    "    latest_step = latest_checkpoint_files(checkpoint_dir, get_step)\n",
    "    netG_A2B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_A2B_{}.pth'.format(latest_step))))\n",
    "    netG_B2A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_B2A_{}.pth'.format(latest_step))))\n",
    "    netD_A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netD_A_{}.pth'.format(latest_step))))\n",
    "    netD_B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netD_B_{}.pth'.format(latest_step))))\n",
    "\n",
    "    optimizer_G.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'optimizer_G_{}.pth'.format(latest_step))))\n",
    "    optimizer_D_A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'optimizer_D_A_{}.pth'.format(latest_step))))\n",
    "    optimizer_D_B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'optimizer_D_B_{}.pth'.format(latest_step))))\n",
    "\n",
    "    lr_scheduler_G.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'lr_scheduler_G_{}.pth'.format(latest_step))))\n",
    "    lr_scheduler_D_A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'lr_scheduler_D_A_{}.pth'.format(latest_step))))\n",
    "    lr_scheduler_D_B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'lr_scheduler_D_B_{}.pth'.format(latest_step))))\n",
    "  \n",
    "  ### Inputs and targets allocations\n",
    "  print(\"---- Allocating the networks ----\".upper())\n",
    "  Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "  input_A = Tensor(batch_size, 3, image_size, image_size)\n",
    "  input_B = Tensor(batch_size, 3, image_size, image_size)\n",
    "  \n",
    "  target_real = Variable(Tensor(batch_size).fill_(real_label), requires_grad=False)\n",
    "  target_fake = Variable(Tensor(batch_size).fill_(0.), requires_grad=False)\n",
    "\n",
    "  mask_non_shadow = Variable(Tensor(batch_size, 1, image_size, image_size).fill_(-1.0), \n",
    "                             requires_grad=False)  # Ml\n",
    "  fake_A_buffer = ImagePool(pool_size)\n",
    "  fake_B_buffer = ImagePool(pool_size)\n",
    "\n",
    "  # Data loader\n",
    "  dataloader = DataLoader(UnalignedDataset(A_dir, B_dir, image_size), \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "  mask_queue = QueueMask(queue_size=dataloader.__len__() / 4)\n",
    "\n",
    "  print('---- Start training ----'.upper())\n",
    "  iter_num = latest_step * dataloader.__len__()\n",
    "  start_time = time.time()\n",
    "  try:\n",
    "    for epoch in range(latest_step, n_epochs):\n",
    "      for i, batch in enumerate(dataloader):\n",
    "\n",
    "        real_A = Variable(input_A.copy_(batch['A']))\n",
    "        real_B = Variable(input_B.copy_(batch['B']))\n",
    "        \n",
    "        # Generators optimizing\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        ## Identity loss\n",
    "        same_B = netG_A2B(real_B)\n",
    "        identity_G_A2B_loss = criterion_identity(same_B, real_B)\n",
    "        identity_G_B2A_loss = criterion_identity(netG_B2A(real_A, mask_non_shadow), real_A)\n",
    "\n",
    "        ## GAN Loss\n",
    "        fake_B = netG_A2B(real_A)\n",
    "        gan_G_A2B_loss = criterion_GAN(netD_B(fake_B), target_real)\n",
    "\n",
    "        mask_queue.insert(mask_generator(real_A, fake_B))\n",
    "\n",
    "        mask_use = mask_queue.rand_item()\n",
    "        fake_A = netG_B2A(real_B, mask_use)\n",
    "        gan_G_B2A_loss = criterion_GAN(netD_A(fake_A), target_real)\n",
    "\n",
    "        ## Cycle loss\n",
    "        recovered_A = netG_B2A(fake_B, mask_queue.last_item())\n",
    "        cycle_G_ABA_loss = criterion_cycle(recovered_A, real_A)\n",
    "\n",
    "        recovered_B = netG_A2B(fake_A)\n",
    "        cycle_G_BAB_loss = criterion_cycle(recovered_B, real_B)\n",
    "\n",
    "        ## Total loss and optimizing\n",
    "        loss_G = identity_lambda * (identity_G_A2B_loss + identity_G_B2A_loss) + \\\n",
    "          (lambda1 * cycle_G_ABA_loss + lambda2 * cycle_G_BAB_loss) + (gan_G_A2B_loss + gan_G_B2A_loss)\n",
    "        loss_G.backward()\n",
    "\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Discriminator A optimizing \n",
    "        optimizer_D_A.zero_grad()\n",
    "        \n",
    "        # real loss\n",
    "        real_D_A = netD_A(real_A)\n",
    "        real_D_A_loss = criterion_GAN(real_D_A, target_real)\n",
    "        \n",
    "        # fake loss\n",
    "        fake_A = fake_A_buffer.sample(fake_A)\n",
    "        fake_D_A = netD_A(fake_A.detach())\n",
    "        fake_D_A_loss = criterion_GAN(fake_D_A, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_A = 0.5 * (real_D_A_loss + fake_D_A_loss)\n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "        \n",
    "        \n",
    "        # Discriminator B optimizing\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        # real loss\n",
    "        real_D_B = netD_B(real_B)\n",
    "        real_D_B_loss = criterion_GAN(real_D_B, target_real)\n",
    "        \n",
    "        # fake loss\n",
    "        fake_B = fake_B_buffer.sample(fake_B)\n",
    "        fake_D_B = netD_B(fake_B.detach())\n",
    "        fake_D_B_loss = criterion_GAN(fake_D_B, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_B = 0.5 * (real_D_B_loss + fake_D_B_loss)\n",
    "        loss_D_B.backward()\n",
    "\n",
    "        optimizer_D_B.step()\n",
    "        iter_num += 1\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "          log = '[iter %d], [loss_G %.5f], [loss_G_identity %.5f], [loss_G_GAN %.5f],' \\\n",
    "              '[loss_G_cycle %.5f], [loss_D %.5f]' % \\\n",
    "              (iter_num, loss_G, (identity_G_A2B_loss + identity_G_B2A_loss), (gan_G_A2B_loss + gan_G_B2A_loss),\n",
    "              (cycle_G_ABA_loss + cycle_G_BAB_loss), (loss_D_A + loss_D_B))\n",
    "          print(log)\n",
    "\n",
    "          img_fake_A = 0.5 * (fake_A.detach().data + 1.0)\n",
    "          img_fake_A = (to_pil(img_fake_A.data.squeeze(0).cpu()))\n",
    "          img_fake_A.save(os.path.join(images_dir, 'fake_A_{}.png'.format(iter_num)))\n",
    "\n",
    "          img_fake_B = 0.5 * (fake_B.detach().data + 1.0)\n",
    "          img_fake_B = (to_pil(img_fake_B.data.squeeze(0).cpu()))\n",
    "          img_fake_B.save(os.path.join(images_dir, 'fake_B_{}.png'.format(iter_num)))\n",
    "          duration = time.time() - start_time\n",
    "          if duration > 6 * 3600:\n",
    "            print(\"---- 6 hours limit reached ----\".upper())\n",
    "            break\n",
    "          print(\"Time from start : \", time.time() - start_time)\n",
    "\n",
    "\n",
    "      # schedulers\n",
    "      lr_scheduler_G.step()\n",
    "      lr_scheduler_D_A.step()\n",
    "      lr_scheduler_D_B.step()\n",
    "\n",
    "      # checkpoints\n",
    "      if (epoch + 1) % 5 == 0:\n",
    "        print(\"Saving the checkpoint - {}\".format(epoch + 1))\n",
    "        torch.save(netG_A2B.state_dict(), os.path.join(checkpoint_dir, 'netG_A2B_{}.pth'.format(epoch+1)))\n",
    "        torch.save(netG_B2A.state_dict(), os.path.join(checkpoint_dir, 'netG_B2A_{}.pth'.format(epoch+1)))\n",
    "        torch.save(netD_A.state_dict(), os.path.join(checkpoint_dir, 'netD_A_{}.pth'.format(epoch+1)))\n",
    "        torch.save(netD_B.state_dict(), os.path.join(checkpoint_dir, 'netD_B_{}.pth'.format(epoch+1)))\n",
    "\n",
    "        torch.save(optimizer_G.state_dict(), os.path.join(checkpoint_dir, 'optimizer_G_{}.pth'.format(epoch+1)))\n",
    "        torch.save(optimizer_D_A.state_dict(), os.path.join(checkpoint_dir, 'optimizer_D_A_{}.pth'.format(epoch+1)))\n",
    "        torch.save(optimizer_D_B.state_dict(), os.path.join(checkpoint_dir, 'optimizer_D_B_{}.pth'.format(epoch+1)))\n",
    "\n",
    "        torch.save(lr_scheduler_G.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_G_{}.pth'.format(epoch+1)))\n",
    "        torch.save(lr_scheduler_D_A.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_D_A_{}.pth'.format(epoch+1)))\n",
    "        torch.save(lr_scheduler_D_B.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_D_B_{}.pth'.format(epoch+1)))\n",
    "      \n",
    "      if epoch > 200:\n",
    "        print(\"---- Reached the 200 epochs ----\".upper())\n",
    "        break\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"---- EXCEPTION ----\")\n",
    "    print(e)\n",
    "    raise e\n",
    "    print(\"@ line {}\".format(sys.exc_info()[-1].tb_lineno))\n",
    "  finally:\n",
    "    # save the checkpoint\n",
    "    \n",
    "    print(\"Saving the checkpoint - {}\".format(epoch + 1))\n",
    "    torch.save(netG_A2B.state_dict(), os.path.join(checkpoint_dir, 'netG_A2B_{}.pth'.format(epoch+1)))\n",
    "    torch.save(netG_B2A.state_dict(), os.path.join(checkpoint_dir, 'netG_B2A_{}.pth'.format(epoch+1)))\n",
    "    torch.save(netD_A.state_dict(), os.path.join(checkpoint_dir, 'netD_A_{}.pth'.format(epoch+1)))\n",
    "    torch.save(netD_B.state_dict(), os.path.join(checkpoint_dir, 'netD_B_{}.pth'.format(epoch+1)))\n",
    "\n",
    "    torch.save(optimizer_G.state_dict(), os.path.join(checkpoint_dir, 'optimizer_G_{}.pth'.format(epoch+1)))\n",
    "    torch.save(optimizer_D_A.state_dict(), os.path.join(checkpoint_dir, 'optimizer_D_A_{}.pth'.format(epoch+1)))\n",
    "    torch.save(optimizer_D_B.state_dict(), os.path.join(checkpoint_dir, 'optimizer_D_B_{}.pth'.format(epoch+1)))\n",
    "\n",
    "    torch.save(lr_scheduler_G.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_G_{}.pth'.format(epoch+1)))\n",
    "    torch.save(lr_scheduler_D_A.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_D_A_{}.pth'.format(epoch+1)))\n",
    "    torch.save(lr_scheduler_D_B.state_dict(), os.path.join(checkpoint_dir, 'lr_scheduler_D_B_{}.pth'.format(epoch+1)))\n",
    "\n",
    "    print(\"---- Finish ----\".upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22278354,
     "status": "ok",
     "timestamp": 1579846076968,
     "user": {
      "displayName": "Vlad Andronik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKTHOk9ud4cZtCOV8G0IGkRw4LOUbSfAFI8aQG8A=s64",
      "userId": "00447066830077822735"
     },
     "user_tz": -120
    },
    "id": "KmMZhRIp4y36",
    "outputId": "aa8e74f4-38fc-4bcf-8aa0-39384cc74482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- DEFINE THE NETWORKS ----\n",
      "---- INITIALIZING THE NETWORKS ----\n",
      "---- DEFINE THE LOSSES ----\n",
      "---- DEFINE THE SCHEDULERS AND OPTIMIZERS ----\n",
      "---- RESUME TRAINING FROM THE LATEST CHECKPOINT ----\n",
      "---- ALLOCATING THE NETWORKS ----\n",
      "---- START TRAINING ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 342301], [loss_G 2.39170], [loss_G_identity 0.07929], [loss_G_GAN 1.67406],[loss_G_cycle 0.06780], [loss_D 0.01205]\n",
      "Time from start :  2.43892502784729\n",
      "[iter 343301], [loss_G 2.40191], [loss_G_identity 0.07386], [loss_G_GAN 1.61789],[loss_G_cycle 0.07471], [loss_D 0.09941]\n",
      "Time from start :  707.6419966220856\n",
      "[iter 344257], [loss_G 2.15431], [loss_G_identity 0.20001], [loss_G_GAN 1.06660],[loss_G_cycle 0.09877], [loss_D 0.08525]\n",
      "Time from start :  1426.5825719833374\n",
      "[iter 345257], [loss_G 2.27064], [loss_G_identity 0.10003], [loss_G_GAN 1.42336],[loss_G_cycle 0.07973], [loss_D 0.03857]\n",
      "Time from start :  2134.9565091133118\n",
      "[iter 346213], [loss_G 1.95389], [loss_G_identity 0.09544], [loss_G_GAN 1.00708],[loss_G_cycle 0.08991], [loss_D 0.06158]\n",
      "Time from start :  2813.0236287117004\n",
      "[iter 347213], [loss_G 1.89872], [loss_G_identity 0.10401], [loss_G_GAN 1.21937],[loss_G_cycle 0.06273], [loss_D 0.01771]\n",
      "Time from start :  3522.4053750038147\n",
      "[iter 348169], [loss_G 2.34890], [loss_G_identity 0.10217], [loss_G_GAN 1.59746],[loss_G_cycle 0.07004], [loss_D 0.10566]\n",
      "Time from start :  4200.7405779361725\n",
      "[iter 349169], [loss_G 2.88081], [loss_G_identity 0.09245], [loss_G_GAN 1.91421],[loss_G_cycle 0.09204], [loss_D 0.17669]\n",
      "Time from start :  4909.813965082169\n",
      "[iter 350125], [loss_G 2.94426], [loss_G_identity 0.12139], [loss_G_GAN 2.02765],[loss_G_cycle 0.08559], [loss_D 0.01923]\n",
      "Time from start :  5587.3856382369995\n",
      "[iter 351125], [loss_G 2.06335], [loss_G_identity 0.07839], [loss_G_GAN 1.32242],[loss_G_cycle 0.07017], [loss_D 0.08565]\n",
      "Time from start :  6295.921591043472\n",
      "Saving the checkpoint - 180\n",
      "[iter 352081], [loss_G 1.92209], [loss_G_identity 0.07173], [loss_G_GAN 1.20930],[loss_G_cycle 0.06769], [loss_D 0.11080]\n",
      "Time from start :  6974.498116731644\n",
      "[iter 353081], [loss_G 2.13351], [loss_G_identity 0.06292], [loss_G_GAN 1.38891],[loss_G_cycle 0.07131], [loss_D 0.07027]\n",
      "Time from start :  7682.81428194046\n",
      "[iter 354037], [loss_G 2.83287], [loss_G_identity 0.09045], [loss_G_GAN 1.62088],[loss_G_cycle 0.11668], [loss_D 0.12426]\n",
      "Time from start :  8360.460310459137\n",
      "[iter 355037], [loss_G 2.69661], [loss_G_identity 0.09184], [loss_G_GAN 1.89940],[loss_G_cycle 0.07513], [loss_D 0.03531]\n",
      "Time from start :  9069.250611782074\n",
      "[iter 355993], [loss_G 2.31419], [loss_G_identity 0.06386], [loss_G_GAN 1.62492],[loss_G_cycle 0.06573], [loss_D 0.04936]\n",
      "Time from start :  9746.238772392273\n",
      "[iter 356993], [loss_G 2.07544], [loss_G_identity 0.07949], [loss_G_GAN 1.17591],[loss_G_cycle 0.08598], [loss_D 0.04607]\n",
      "Time from start :  10454.403715372086\n",
      "[iter 357949], [loss_G 1.89650], [loss_G_identity 0.08965], [loss_G_GAN 0.97411],[loss_G_cycle 0.08776], [loss_D 0.15262]\n",
      "Time from start :  11132.120579242706\n",
      "[iter 358949], [loss_G 2.22162], [loss_G_identity 0.10911], [loss_G_GAN 1.44414],[loss_G_cycle 0.07229], [loss_D 0.21166]\n",
      "Time from start :  11840.914346694946\n",
      "[iter 359905], [loss_G 1.73600], [loss_G_identity 0.11897], [loss_G_GAN 0.88811],[loss_G_cycle 0.07884], [loss_D 0.04365]\n",
      "Time from start :  12518.540900945663\n",
      "[iter 360905], [loss_G 2.72870], [loss_G_identity 0.07868], [loss_G_GAN 1.94336],[loss_G_cycle 0.07460], [loss_D 0.25574]\n",
      "Time from start :  13226.603470563889\n",
      "Saving the checkpoint - 185\n",
      "[iter 361861], [loss_G 2.21905], [loss_G_identity 0.07732], [loss_G_GAN 1.51438],[loss_G_cycle 0.06660], [loss_D 0.02196]\n",
      "Time from start :  13905.832386016846\n",
      "[iter 362861], [loss_G 2.96745], [loss_G_identity 0.08554], [loss_G_GAN 2.19132],[loss_G_cycle 0.07334], [loss_D 0.08692]\n",
      "Time from start :  14614.566884279251\n",
      "[iter 363817], [loss_G 2.42894], [loss_G_identity 0.09614], [loss_G_GAN 1.02943],[loss_G_cycle 0.13514], [loss_D 0.85862]\n",
      "Time from start :  15292.154219150543\n",
      "[iter 364817], [loss_G 3.77586], [loss_G_identity 0.07064], [loss_G_GAN 2.86776],[loss_G_cycle 0.08728], [loss_D 0.07314]\n",
      "Time from start :  16000.668661117554\n",
      "[iter 365773], [loss_G 2.38193], [loss_G_identity 0.08031], [loss_G_GAN 1.55657],[loss_G_cycle 0.07852], [loss_D 0.13292]\n",
      "Time from start :  16678.241717338562\n",
      "[iter 366773], [loss_G 2.61014], [loss_G_identity 0.09202], [loss_G_GAN 1.70490],[loss_G_cycle 0.08592], [loss_D 0.01571]\n",
      "Time from start :  17387.06409072876\n",
      "[iter 367729], [loss_G 3.72485], [loss_G_identity 0.12003], [loss_G_GAN 2.82410],[loss_G_cycle 0.08407], [loss_D 0.05142]\n",
      "Time from start :  18064.661699056625\n",
      "[iter 368729], [loss_G 2.24025], [loss_G_identity 0.07760], [loss_G_GAN 1.44157],[loss_G_cycle 0.07599], [loss_D 0.03201]\n",
      "Time from start :  18773.39448618889\n",
      "[iter 369685], [loss_G 2.36253], [loss_G_identity 0.07932], [loss_G_GAN 1.38402],[loss_G_cycle 0.09389], [loss_D 0.04316]\n",
      "Time from start :  19450.90456676483\n",
      "[iter 370685], [loss_G 2.18193], [loss_G_identity 0.20230], [loss_G_GAN 1.30232],[loss_G_cycle 0.07785], [loss_D 0.03328]\n",
      "Time from start :  20159.474325418472\n",
      "Saving the checkpoint - 190\n",
      "[iter 371641], [loss_G 2.17435], [loss_G_identity 0.20120], [loss_G_GAN 1.33045],[loss_G_cycle 0.07433], [loss_D 0.18142]\n",
      "Time from start :  20838.527089595795\n",
      "[iter 372641], [loss_G 2.76909], [loss_G_identity 0.09941], [loss_G_GAN 1.86874],[loss_G_cycle 0.08506], [loss_D 0.04335]\n",
      "Time from start :  21547.09466099739\n",
      "[iter 373597], [loss_G 2.69783], [loss_G_identity 0.10307], [loss_G_GAN 1.76086],[loss_G_cycle 0.08854], [loss_D 0.14793]\n",
      "---- 6 HOURS LIMIT REACHED ----\n",
      "[iter 373598], [loss_G 3.21007], [loss_G_identity 0.08265], [loss_G_GAN 2.28072],[loss_G_cycle 0.08880], [loss_D 0.01991]\n",
      "---- 6 HOURS LIMIT REACHED ----\n",
      "[iter 373599], [loss_G 2.69731], [loss_G_identity 0.07342], [loss_G_GAN 1.80614],[loss_G_cycle 0.08545], [loss_D 0.11049]\n",
      "---- 6 HOURS LIMIT REACHED ----\n",
      "[iter 373600], [loss_G 3.56856], [loss_G_identity 0.08197], [loss_G_GAN 2.69717],[loss_G_cycle 0.08304], [loss_D 0.03239]\n",
      "---- 6 HOURS LIMIT REACHED ----\n",
      "Saving the checkpoint - 195\n",
      "[iter 373601], [loss_G 1.94973], [loss_G_identity 0.09339], [loss_G_GAN 1.19580],[loss_G_cycle 0.07072], [loss_D 0.03903]\n",
      "---- 6 HOURS LIMIT REACHED ----\n",
      "[iter 373602], [loss_G 2.99932], [loss_G_identity 0.07575], [loss_G_GAN 1.62736],[loss_G_cycle 0.13341], [loss_D 0.05304]\n",
      "---- 6 HOURS LIMIT REACHED ----\n",
      "[iter 373603], [loss_G 2.13938], [loss_G_identity 0.17527], [loss_G_GAN 1.22964],[loss_G_cycle 0.08221], [loss_D 0.03052]\n",
      "---- 6 HOURS LIMIT REACHED ----\n",
      "[iter 373604], [loss_G 2.66193], [loss_G_identity 0.07915], [loss_G_GAN 1.64233],[loss_G_cycle 0.09800], [loss_D 0.29074]\n",
      "---- 6 HOURS LIMIT REACHED ----\n",
      "[iter 373605], [loss_G 1.98773], [loss_G_identity 0.09843], [loss_G_GAN 1.25532],[loss_G_cycle 0.06832], [loss_D 0.11170]\n",
      "---- 6 HOURS LIMIT REACHED ----\n",
      "Saving the checkpoint - 200\n",
      "Saving the checkpoint - 200\n",
      "---- FINISH ----\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "94gaOPlf1q2J"
   },
   "outputs": [],
   "source": [
    "images_paths = glob.glob(os.path.join(images_dir, '*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Qm1FrKDUEN1R"
   },
   "outputs": [],
   "source": [
    "def get_step_(filename):\n",
    "  match = re.findall(r'(\\d+).png', filename)[0]\n",
    "  return int(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aqpzjvENEYjD"
   },
   "outputs": [],
   "source": [
    "ind = list(map(get_step, images_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9LxMFQ7OEeBO"
   },
   "outputs": [],
   "source": [
    "k = 30 * 2\n",
    "im_ind = sorted(zip(images_paths, ind), reverse=True, key=lambda x: x[1])[k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SlW8HNbxE9Yl"
   },
   "outputs": [],
   "source": [
    "to_del_path = [x[0] for x in im_ind]\n",
    "_ = [os.remove(path) for path in to_del_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsCodjOft9nj"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wsqPZOLkYUA8"
   },
   "outputs": [],
   "source": [
    "def read_paths(path):\n",
    "  with open(path, 'rb') as f:\n",
    "    paths = pickle.load(f)\n",
    "  return paths\n",
    "\n",
    "def mkdir(path):\n",
    "  try:\n",
    "    os.mkdir(path)\n",
    "  except FileExistsError as e:\n",
    "    pass\n",
    "\n",
    "def save_test(A_path, B_path, save_path):\n",
    "  start_time = time.time()\n",
    "  A_paths = read_paths(A_path)\n",
    "  B_paths = read_paths(B_path)\n",
    "  \n",
    "  assert len(A_paths) == len(B_paths)\n",
    "  # read and preprocess the test images\n",
    "  mkdir(save_path)\n",
    "  mkdir(os.path.join(save_path, 'A'))\n",
    "  mkdir(os.path.join(save_path, 'B'))\n",
    "\n",
    "  mkdir(os.path.join(save_path, 'A_B'))\n",
    "  mkdir(os.path.join(save_path, 'B_A'))\n",
    "\n",
    "  mkdir(os.path.join(save_path, 'masks'))\n",
    "\n",
    "  # save domain images\n",
    "  # print('---- Saving the images for domains ----'.upper())\n",
    "  # save_images(A_paths, os.path.join(save_path, 'A'), 'A')\n",
    "  # save_images(B_paths, os.path.join(save_path, 'B'), 'B')\n",
    "\n",
    "  # load the model\n",
    "  print(\"---- Loading the models ----\".upper())\n",
    "  netG_A2B = Generator_S2F(input_nc).to(device)\n",
    "  netG_B2A = Generator_F2S(input_nc+1, output_nc).to(device)\n",
    "\n",
    "\n",
    "  # load latest checkpoint\n",
    "  latest_step = latest_checkpoint_files(checkpoint_dir, get_step)\n",
    "  netG_A2B.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_A2B_{}.pth'.format(latest_step))))\n",
    "  netG_B2A.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'netG_B2A_{}.pth'.format(latest_step))))\n",
    "\n",
    "  # turn the validation mode\n",
    "  netG_A2B.eval()\n",
    "  netG_B2A.eval()\n",
    "\n",
    "  # input tensors\n",
    "  Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "  input_A = Tensor(batch_size, input_nc, image_size, image_size, 3)\n",
    "  input_B = Tensor(batch_size, output_nc, image_size, image_size, 3)\n",
    "\n",
    "  # input transformations\n",
    "  img_transforms = transforms.Compose([\n",
    "                                       transforms.Resize((image_size, image_size), interpolation=Image.BICUBIC),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((.5,.5,.5),(.5,.5,.5))\n",
    "  ])\n",
    "  to_pil = transforms.ToPILImage()\n",
    "\n",
    "  # start inference\n",
    "  print(\"--- Start inference ----\".upper())\n",
    "  image_queue = QueueMask(queue_size=mask_queue_size)\n",
    "  for i,(path_A, path_B) in enumerate(zip(A_paths, B_paths)):\n",
    "    image_A = Image.open(path_A).convert(\"RGB\")\n",
    "    image_B = Image.open(path_A).convert(\"RGB\")\n",
    "\n",
    "    im_A = (img_transforms(image_A).unsqueeze(0)).to(device)\n",
    "    im_B = (img_transforms(image_B).unsqueeze(0)).to(device)\n",
    "\n",
    "    Image.fromarray(np.array(transforms.Resize((image_size, image_size))(image_A))).save(os.path.join(save_path, 'A', 'A_{}.jpg'.format(i)))\n",
    "    Image.fromarray(np.array(transforms.Resize((image_size, image_size))(image_B))).save(os.path.join(save_path, 'B', 'B_{}.jpg'.format(i)))\n",
    "\n",
    "    # generate A -> B\n",
    "    A_B = netG_A2B(im_A)\n",
    "    w,h = image_A.size\n",
    "\n",
    "    current_mask = mask_generator(A_B, im_A)\n",
    "    image_queue.insert(current_mask)\n",
    "    A_B = .5 * (A_B + 1)\n",
    "    A_B = np.array((to_pil(A_B.data.squeeze(0).cpu())))\n",
    "    Image.fromarray(A_B).save(os.path.join(save_path, 'A_B', 'A_B_{}.jpg'.format(i)))\n",
    "\n",
    "    # generate B -> A\n",
    "    mask = image_queue.rand_item()\n",
    "    B_A = netG_B2A(im_B, mask)\n",
    "    w,h = image_B.size\n",
    "\n",
    "    B_A = .5 * (B_A + 1)\n",
    "    B_A = np.array((to_pil(B_A.data.squeeze(0).cpu())))\n",
    "    Image.fromarray(B_A).save(os.path.join(save_path, 'B_A', 'B_A_{}.jpg'.format(i)))\n",
    "\n",
    "    mask_cpu = .5 * (current_mask + 1)\n",
    "    mask_cpu = np.array((to_pil(mask_cpu.data.squeeze(0).cpu())))\n",
    "    Image.fromarray(mask_cpu).save(os.path.join(save_path, 'masks', 'mask_{}.jpg'.format(i)))\n",
    "\n",
    "  print(\"---- Inference time : {} ----\".format(time.time() - start_time).upper())\n",
    "  \n",
    "\n",
    "\n",
    "def save_images(image_paths, save_path, domain):\n",
    "  try:\n",
    "    os.mkdir(save_path)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  for i in range(len(image_paths)):\n",
    "    img = plt.imread(image_paths[i])\n",
    "    plt.imsave(os.path.join(save_path,'{}_{}.jpg'.format(domain, i)), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "h8ndFahettfZ"
   },
   "outputs": [],
   "source": [
    "A_dir_inf = 'mask_shadow_gan/results/test_paths/shadow_path.pickle'\n",
    "B_dir_inf = 'mask_shadow_gan/results/test_paths/free_path.pickle'\n",
    "results_dir = 'mask_shadow_gan/results/msg_200/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26799,
     "status": "ok",
     "timestamp": 1580411310758,
     "user": {
      "displayName": "Vlad Andronik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKTHOk9ud4cZtCOV8G0IGkRw4LOUbSfAFI8aQG8A=s64",
      "userId": "00447066830077822735"
     },
     "user_tz": -120
    },
    "id": "X2nINWzMoDqv",
    "outputId": "0456c06f-6fe1-4f6f-883e-92cc29e32b8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- LOADING THE MODELS ----\n",
      "--- START INFERENCE ----\n",
      "---- INFERENCE TIME : 26.246599912643433 ----\n"
     ]
    }
   ],
   "source": [
    "save_test(A_dir_inf, B_dir_inf, results_dir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOSlB5Uhd+Vwz1Aji12+oJ6",
   "name": "mask_shadow_gan_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
